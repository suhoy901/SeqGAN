{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T10:58:44.148963Z",
     "start_time": "2018-06-16T10:58:44.128633Z"
    }
   },
   "source": [
    "# SeqGAN(Sequence Generative Adverserial Networks with Policy Grandient)\n",
    "\n",
    "- https://arxiv.org/abs/1609.05473\n",
    "- Code Reference : https://github.com/suragnair/seqGAN\n",
    "\n",
    "### 특징\n",
    "- GAN 모형에 Reinforcement Learning을 적용한 최초의 시도\n",
    "- **MCTS** : Heuristic Search\n",
    "- **GAN**\n",
    "---\n",
    "### 문제점\n",
    "**Sequence generation**에 GAN모형을 적용하기 위해서는 2가지의 문제점을 극복해야 함\n",
    "1. GAN의 Discriminator는 오직 전체 sequence에 대한 score, loss를 계산 가능. 부분적으로 생성된 현재 Sequence와 완성된 미래 Sequence의 score 사이의 균형을 맞추기가 어려움 점이 존재함\n",
    "\n",
    "2. real-valued, continuous data 생성을 위해 모델링된 GAN의 Generator는 discrete token으로 구성된 sequence generation에 적용하기가 어려움\n",
    " - generated data가 discrete token인 경우, limited dictionary space에서 slight change(gradient)와 대응하는 token이 존재하지 않을 가능성이 크므로 direct gradient가 불가능함\n",
    " \n",
    "### 제안방법\n",
    "1. SeqGAN은 Generator를 sotchastic policy(REINFORCE)를 정의하고 바로 gradient policy update가 가능하게 함으로써 generator differenciation problem을 우회함\n",
    "2. 완전한 sequence에 대한 D의 판단 score가 RL의 reward가 되며, MCTS를 통해 중간에 state-action단계로 reward를 전달함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T10:58:44.148963Z",
     "start_time": "2018-06-16T10:58:44.128633Z"
    }
   },
   "source": [
    "## 접근방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T10:58:44.148963Z",
     "start_time": "2018-06-16T10:58:44.128633Z"
    }
   },
   "source": [
    "![](./source/source_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T10:58:44.148963Z",
     "start_time": "2018-06-16T10:58:44.128633Z"
    }
   },
   "source": [
    "![](./source/source_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T10:58:44.148963Z",
     "start_time": "2018-06-16T10:58:44.128633Z"
    }
   },
   "source": [
    "## Algorithm process\n",
    "![](./source/pseudo_code.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T10:58:44.148963Z",
     "start_time": "2018-06-16T10:58:44.128633Z"
    }
   },
   "source": [
    "## 1. Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:13:54.654857Z",
     "start_time": "2018-06-18T16:13:54.648729Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import torch.nn.init as init\n",
    "import torch.autograd as autograd\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T10:58:44.148963Z",
     "start_time": "2018-06-16T10:58:44.128633Z"
    }
   },
   "source": [
    "## 2. Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:13:55.634416Z",
     "start_time": "2018-06-18T16:13:55.492013Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_generator_batch(samples, start_letter=0, gpu=False):\n",
    "    \"\"\"\n",
    "    Takes samples (a batch) and returns\n",
    "    Inputs: samples, start_letter, cuda\n",
    "        - samples: batch_size x seq_len (Tensor with a sample in each row)\n",
    "    Returns: inp, target\n",
    "        - inp: batch_size x seq_len (same as target, but with start_letter prepended)\n",
    "        - target: batch_size x seq_len (Variable same as samples)\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size, seq_len = samples.size()\n",
    "\n",
    "    inp = torch.zeros(batch_size, seq_len)\n",
    "    target = samples\n",
    "    inp[:, 0] = start_letter\n",
    "    inp[:, 1:] = target[:, :seq_len-1]\n",
    "\n",
    "    inp = autograd.Variable(inp).type(torch.LongTensor)\n",
    "    target = autograd.Variable(target).type(torch.LongTensor)\n",
    "\n",
    "    if gpu:\n",
    "        inp = inp.cuda()\n",
    "        target = target.cuda()\n",
    "\n",
    "    return inp, target\n",
    "\n",
    "\n",
    "def prepare_discriminator_data(pos_samples, neg_samples, gpu=False):\n",
    "    \"\"\"\n",
    "    Takes positive (target) samples, negative (generator) samples and prepares inp and target data for discriminator.\n",
    "    Inputs: pos_samples, neg_samples\n",
    "        - pos_samples: pos_size x seq_len\n",
    "        - neg_samples: neg_size x seq_len\n",
    "    Returns: inp, target\n",
    "        - inp: (pos_size + neg_size) x seq_len\n",
    "        - target: pos_size + neg_size (boolean 1/0)\n",
    "    \"\"\"\n",
    "\n",
    "    inp = torch.cat((pos_samples, neg_samples), 0).type(torch.LongTensor)\n",
    "    target = torch.ones(pos_samples.size()[0] + neg_samples.size()[0])\n",
    "    target[pos_samples.size()[0]:] = 0\n",
    "\n",
    "    # shuffle\n",
    "    perm = torch.randperm(target.size()[0])\n",
    "    target = target[perm]\n",
    "    inp = inp[perm]\n",
    "\n",
    "    inp = autograd.Variable(inp)\n",
    "    target = autograd.Variable(target)\n",
    "\n",
    "    if gpu:\n",
    "        inp = inp.cuda()\n",
    "        target = target.cuda()\n",
    "\n",
    "    return inp, target\n",
    "\n",
    "\n",
    "def batchwise_sample(gen, num_samples, batch_size):\n",
    "    \"\"\"\n",
    "    Sample num_samples samples batch_size samples at a time from gen.\n",
    "    Does not require gpu since gen.sample() takes care of that.\n",
    "    \"\"\"\n",
    "\n",
    "    samples = []\n",
    "    for i in range(int(math.ceil(num_samples/float(batch_size)))):\n",
    "        samples.append(gen.sample(batch_size))\n",
    "\n",
    "    return torch.cat(samples, 0)[:num_samples]\n",
    "\n",
    "def batchwise_oracle_nll(gen, oracle, num_samples, batch_size, max_seq_len, start_letter=0, gpu=False):\n",
    "    s = batchwise_sample(gen, num_samples, batch_size)\n",
    "    oracle_nll = 0\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        inp, target = prepare_generator_batch(s[i:i+batch_size], start_letter, gpu)\n",
    "        oracle_loss = oracle.batchNLLLoss(inp, target) / max_seq_len\n",
    "        oracle_nll += oracle_loss.data[0]\n",
    "\n",
    "    return oracle_nll/(num_samples/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T10:58:44.148963Z",
     "start_time": "2018-06-16T10:58:44.128633Z"
    }
   },
   "source": [
    "# 3. Sequence Generator\n",
    "### Objective : to maximize the expected reward\n",
    "\n",
    "$$J(\\theta) = E\\big[R_T | s_0, \\theta \\big] = \\sum_{y_{1} \\in Y} G_{\\theta}(y_1 | s_0) \\dot{} Q_{D_{\\phi}}^{G_{\\theta}}(s_0, y_1) $$\n",
    "\n",
    "\n",
    "### Monte Carlo Tree Search\n",
    "\n",
    "$$\\Big\\{ Y_{1:T}^{1}, ..., Y_{1:T}^N\\Big\\} = MC^{G_{\\beta}} \\big(Y_{1:t}; N \\big)$$\n",
    "\n",
    "### action-value function\n",
    "\n",
    "$$Q_{D_{\\phi}}^{G_{\\theta}}\\big(s = Y_{1:t-1}, a = y_t\\big) = $$\n",
    "\n",
    "$$\\begin{cases} \n",
    "    \\frac{1}{N} \\sum_{n=1}^N  D_{\\phi}(Y_{1:T}^n), Y_{1:T}^n \\in MC^{G_{\\beta}}(Y_{1:T}; N)\\ \\ \\ \\text{for} \\ \\ \\ t < T\\\\\n",
    "    D_{\\phi}(Y_{1:T}) \\ \\ \\ \\text{for} \\ \\ \\ t < T \n",
    "\\end{cases}$$\n",
    "\n",
    "### LSTM\n",
    "![](./source/Sequence_Generative_Model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T10:58:44.148963Z",
     "start_time": "2018-06-16T10:58:44.128633Z"
    }
   },
   "source": [
    "### Policy Gradient\n",
    "- 증명부분 제외\n",
    "\n",
    "![](./source/REINFORCE.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:13:56.489726Z",
     "start_time": "2018-06-18T16:13:56.241859Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, max_seq_len, gpu=False, oracle_init=False):\n",
    "        super(Generator, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.vocab_size = vocab_size\n",
    "        self.gpu = gpu\n",
    "\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim)\n",
    "        self.gru2out = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "        # initialise oracle network with N(0,1)\n",
    "        # otherwise variance of initialisation is very small => high NLL for data sampled from the same model\n",
    "        if oracle_init:\n",
    "            for p in self.parameters():\n",
    "                init.normal(p, 0, 1)\n",
    "                \n",
    "    def init_hidden(self, batch_size = 1):\n",
    "        h = autograd.Variable(torch.zeros(1, batch_size, self.hidden_dim))\n",
    "        \n",
    "        if self.gpu:\n",
    "            return h.cuda()\n",
    "        else:\n",
    "            return h\n",
    "        \n",
    "    def forward(self, inp, hidden):\n",
    "        \"\"\"\n",
    "        Embeds input and applies GRU one token at a time (seq_len = 1)\n",
    "        \"\"\"\n",
    "        # input_dim                                                     # batch_size\n",
    "        emb = self.embeddings(inp)                             # batch_size x embedding_dim         \n",
    "        emb = emb.view(1, -1, self.embedding_dim)      # 1 x batch_size x embedding_dim,   B,T,D\n",
    "        out, hidden = self.gru(emb, hidden)                   # 1 x batch_size x hiddim_dim,         1,B,H\n",
    "        out = self.gru2out(out.view(-1, self.hidden_dim))\n",
    "        out = F.log_softmax(out)\n",
    "        return out, hidden\n",
    "    \n",
    "    def sample(self, num_samples, start_letter=0):\n",
    "        \"\"\"\n",
    "        Samples the network and returns num_samples samples of length max_seq_len.\n",
    "        Outputs: samples, hidden\n",
    "            - samples: num_samples x max_seq_length (a sampled sequence in each row)\n",
    "        \"\"\"\n",
    "        samples = torch.zeros(num_samples, self.max_seq_len).type(torch.LongTensor)\n",
    "\n",
    "        h = self.init_hidden(num_samples)\n",
    "        inp = autograd.Variable(torch.LongTensor([start_letter]*num_samples))\n",
    "\n",
    "        if self.gpu:\n",
    "            samples = samples.cuda()\n",
    "            inp = inp.cuda()\n",
    "\n",
    "        for i in range(self.max_seq_len):\n",
    "            out, h = self.forward(inp, h)               # out: num_samples x vocab_size\n",
    "            out = torch.multinomial(torch.exp(out), 1)  # num_samples x 1 (sampling from each row)\n",
    "            samples[:, i] = out.data\n",
    "\n",
    "            inp = out.view(-1)\n",
    "\n",
    "        return samples\n",
    "\n",
    "        \n",
    "    def batchNLLLoss(self, inp, target):\n",
    "        \"\"\"\n",
    "        Returns the NLL Loss for predicting target sequence.\n",
    "        Inputs: inp, target\n",
    "            - inp: batch_size x seq_len\n",
    "            - target: batch_size x seq_len\n",
    "            inp should be target with <s> (start letter) prepended\n",
    "        \"\"\"\n",
    "        loss_fn = nn.NLLLoss()\n",
    "        batch_size, seq_len = inp.size()\n",
    "        inp = inp.permute(1, 0)                       # seq_len x batch_size\n",
    "        target = target.permute(1, 0)               # seq_len x batch_size\n",
    "        h = self.init_hidden(batch_size)\n",
    "        \n",
    "        loss = 0\n",
    "        for i in range(seq_len):\n",
    "            out, h = self.forward(inp[i], h) # loss\n",
    "            loss += loss_fn(out, target[i])\n",
    "            \n",
    "        return loss # per batch\n",
    "    \n",
    "    # Policy Gradient : REINFORCE\n",
    "    def batchPGLoss(self, inp, target, reward):\n",
    "        \"\"\"\n",
    "        Returns a pseudo-loss that gives corresponding policy gradients (on calling .backward()).\n",
    "        Inspired by the example in http://karpathy.github.io/2016/05/31/rl/\n",
    "        Inputs: inp, target\n",
    "            - inp: batch_size x seq_len\n",
    "            - target: batch_size x seq_len\n",
    "            - reward: batch_size (discriminator reward for each sentence, applied to each token of the corresponding\n",
    "                      sentence)\n",
    "            inp should be target with <s> (start letter) prepended\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = inp.size()\n",
    "        inp = inp.permute(1, 0)\n",
    "        target = target.permute(1, 0)\n",
    "        h = self.init_hidden(batch_size)\n",
    "        \n",
    "        loss = 0\n",
    "        for i in range(seq_len):\n",
    "            out, h = self.forward(inp[i], h)\n",
    "            for j in range(batch_size):\n",
    "                loss += -out[j][target.data[i][j]]* reward[j]\n",
    "                \n",
    "        return loss / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sequence Discriminator Model\n",
    "- 기존 GAN과 동일한 목적함수를 이용해서 $D_{\\phi}$를 학습.\n",
    "- real data = 1, generated data = 0으로 접근하는 이진 분류로 접근\n",
    "- Word Embedding, Conv, MLP,....\n",
    "\n",
    "### Objective function\n",
    "\n",
    "$$\\min_{\\phi} - E_{Y \\sim P_{data}} \\big[ \\text{log} D_{\\phi} \\big( Y \\big) \\big] - E_{Y \\sim G_{\\theta}} \\big[ \\text{log} \\big( 1 - D_{\\theta} \\big( Y\\big) \\big]$$\n",
    "\n",
    "<br><br>\n",
    "\n",
    "![](./source/Sequence_Discriminator_Model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:13:56.665098Z",
     "start_time": "2018-06-18T16:13:56.579766Z"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, max_seq_len, gpu=False, dropout=0.2):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.gpu = gpu\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=2, bidirectional=True, dropout=dropout)\n",
    "        self.gru2hidden = nn.Linear(2*2*hidden_dim, hidden_dim) # (bidirectional * num_layers * hidden_dim, hidden_dim)\n",
    "        self.dropout_linear = nn.Dropout(p=dropout)\n",
    "        self.hidden2out = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def init__hidden(self, batch_size):\n",
    "        h = autograd.Variable(torch.zeros(2*2*1, batch_size, self.hidden_dim))\n",
    "        \n",
    "        if self.gpu:\n",
    "            return h.cuda()\n",
    "        else:\n",
    "            return h\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        # input dim                                                                      # batch_size x seq_len\n",
    "        emb = self.embeddings(input)                                           # batch_size x seq_len x embedding_dim\n",
    "        emb = emb.permute(1, 0, 2)                                             # seq_len x batch_size x embedding_dim\n",
    "        _, hidden = self.gru(emb, hidden)                                      # 4 x batch_size x hidden_dim\n",
    "        hidden = hidden.permute(1, 0, 2).contiguous()                   # batch_size x 4 x hidden\n",
    "        out = self.gru2hidden(hidden.view(-1, 4*self.hidden_dim))  # batch_size x 4*hidden_dim\n",
    "        out = F.tanh(out)\n",
    "        out = self.dropout_linear(out)\n",
    "        out = self.hidden2out(out)                                                # batch_size x 1\n",
    "        out = F.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "    def batchClassify(self, inp):\n",
    "        \"\"\"\n",
    "        Classifies a batch of sequences.\n",
    "        Inputs: inp\n",
    "            - inp: batch_size x seq_len\n",
    "        Returns: out\n",
    "            - out: batch_size ([0,1] score)\n",
    "        \"\"\"\n",
    "        h = self.init__hidden(inp.size()[0])\n",
    "        out = self.forward(inp, h)\n",
    "        return out.view(-1)\n",
    "    \n",
    "    def batchBCELoss(self, inp, target):\n",
    "        \"\"\"\n",
    "        Returns Binary Cross Entropy Loss for discriminator.\n",
    "         Inputs: inp, target\n",
    "            - inp: batch_size x seq_len\n",
    "            - target: batch_size (binary 1/0)\n",
    "        \"\"\"\n",
    "        loss_fn = nn.BCELoss()\n",
    "        h = self.init__hidden(inp.size()[0])\n",
    "        out = self.forward(inp, h)\n",
    "        return loss_fn(out, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:13:56.903045Z",
     "start_time": "2018-06-18T16:13:56.887581Z"
    }
   },
   "outputs": [],
   "source": [
    "CUDA = False\n",
    "VOCAB_SIZE = 5000\n",
    "MAX_SEQ_LEN = 20\n",
    "START_LETTER = 0\n",
    "BATCH_SIZE = 32\n",
    "MLE_TRAIN_EPOCHS = 100\n",
    "ADV_TRAIN_EPOCHS = 50\n",
    "POS_NEG_SAMPLES = 10000\n",
    "\n",
    "GEN_EMBEDDING_DIM = 32\n",
    "GEN_HIDDEN_DIM = 32\n",
    "DIS_EMBEDDING_DIM = 64\n",
    "DIS_HIDDEN_DIM = 64\n",
    "\n",
    "oracle_samples_path = './oracle_samples.trc'\n",
    "oracle_state_dict_path = './oracle_EMBDIM32_HIDDENDIM32_VOCAB5000_MAXSEQLEN20.trc'\n",
    "pretrained_gen_path = './gen_MLEtrain_EMBDIM32_HIDDENDIM32_VOCAB5000_MAXSEQLEN20.trc'\n",
    "pretrained_dis_path = './dis_pretrain_EMBDIM_64_HIDDENDIM64_VOCAB5000_MAXSEQLEN20.trc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:13:58.609549Z",
     "start_time": "2018-06-18T16:13:58.367158Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_generator_MLE(gen, gen_opt, oracle, real_data_samples, epochs):\n",
    "    \"\"\"\n",
    "    Max Likelihood Pretraining for the generator\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        print('epoch %d : ' % (epoch + 1), end='')\n",
    "        sys.stdout.flush()\n",
    "        total_loss = 0\n",
    "\n",
    "        for i in range(0, POS_NEG_SAMPLES, BATCH_SIZE):\n",
    "            inp, target = prepare_generator_batch(real_data_samples[i:i + BATCH_SIZE], start_letter=START_LETTER, gpu=CUDA)\n",
    "            gen_opt.zero_grad()\n",
    "            loss = gen.batchNLLLoss(inp, target)\n",
    "            loss.backward()\n",
    "            gen_opt.step()\n",
    "\n",
    "            total_loss += loss.data[0]\n",
    "\n",
    "            if (i / BATCH_SIZE) % math.ceil(\n",
    "                            math.ceil(POS_NEG_SAMPLES / float(BATCH_SIZE)) / 10.) == 0:  # roughly every 10% of an epoch\n",
    "                print('.', end='')\n",
    "                sys.stdout.flush()\n",
    "\n",
    "        # each loss in a batch is loss per sample\n",
    "        total_loss = total_loss / math.ceil(POS_NEG_SAMPLES / float(BATCH_SIZE)) / MAX_SEQ_LEN\n",
    "\n",
    "        # sample from generator and compute oracle NLL\n",
    "        oracle_loss = batchwise_oracle_nll(gen, oracle, POS_NEG_SAMPLES, BATCH_SIZE, MAX_SEQ_LEN,\n",
    "                                                   start_letter=START_LETTER, gpu=CUDA)\n",
    "\n",
    "        print(' average_train_NLL = %.4f, oracle_sample_NLL = %.4f' % (total_loss, oracle_loss))\n",
    "\n",
    "\n",
    "def train_generator_PG(gen, gen_opt, oracle, dis, num_batches):\n",
    "    \"\"\"\n",
    "    The generator is trained using policy gradients, using the reward from the discriminator.\n",
    "    Training is done for num_batches batches.\n",
    "    \"\"\"\n",
    "\n",
    "    for batch in range(num_batches):\n",
    "        s = gen.sample(BATCH_SIZE*2)        # 64 works best\n",
    "        inp, target = prepare_generator_batch(s, start_letter=START_LETTER, gpu=CUDA)\n",
    "        rewards = dis.batchClassify(target)\n",
    "\n",
    "        gen_opt.zero_grad()\n",
    "        pg_loss = gen.batchPGLoss(inp, target, rewards)\n",
    "        pg_loss.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "    # sample from generator and compute oracle NLL\n",
    "    oracle_loss = batchwise_oracle_nll(gen, oracle, POS_NEG_SAMPLES, BATCH_SIZE, MAX_SEQ_LEN,\n",
    "                                                   start_letter=START_LETTER, gpu=CUDA)\n",
    "\n",
    "    print(' oracle_sample_NLL = %.4f' % oracle_loss)\n",
    "\n",
    "\n",
    "def train_discriminator(discriminator, dis_opt, real_data_samples, generator, oracle, d_steps, epochs):\n",
    "    \"\"\"\n",
    "    Training the discriminator on real_data_samples (positive) and generated samples from generator (negative).\n",
    "    Samples are drawn d_steps times, and the discriminator is trained for epochs epochs.\n",
    "    \"\"\"\n",
    "\n",
    "    # generating a small validation set before training (using oracle and generator)\n",
    "    pos_val = oracle.sample(100)\n",
    "    neg_val = generator.sample(100)\n",
    "    val_inp, val_target = prepare_discriminator_data(pos_val, neg_val, gpu=CUDA)\n",
    "\n",
    "    for d_step in range(d_steps):\n",
    "        s = batchwise_sample(generator, POS_NEG_SAMPLES, BATCH_SIZE)\n",
    "        dis_inp, dis_target = prepare_discriminator_data(real_data_samples, s, gpu=CUDA)\n",
    "        for epoch in range(epochs):\n",
    "            print('d-step %d epoch %d : ' % (d_step + 1, epoch + 1), end='')\n",
    "            sys.stdout.flush()\n",
    "            total_loss = 0\n",
    "            total_acc = 0\n",
    "\n",
    "            for i in range(0, 2 * POS_NEG_SAMPLES, BATCH_SIZE):\n",
    "                inp, target = dis_inp[i:i + BATCH_SIZE], dis_target[i:i + BATCH_SIZE]\n",
    "                dis_opt.zero_grad()\n",
    "                out = discriminator.batchClassify(inp)\n",
    "                loss_fn = nn.BCELoss()\n",
    "                loss = loss_fn(out, target)\n",
    "                loss.backward()\n",
    "                dis_opt.step()\n",
    "\n",
    "                total_loss += loss.data[0]\n",
    "                total_acc += torch.sum((out>0.5)==(target>0.5)).data[0]\n",
    "\n",
    "                if (i / BATCH_SIZE) % math.ceil(math.ceil(2 * POS_NEG_SAMPLES / float(\n",
    "                        BATCH_SIZE)) / 10.) == 0:  # roughly every 10% of an epoch\n",
    "                    print('.', end='')\n",
    "                    sys.stdout.flush()\n",
    "\n",
    "            total_loss /= math.ceil(2 * POS_NEG_SAMPLES / float(BATCH_SIZE))\n",
    "            total_acc /= float(2 * POS_NEG_SAMPLES)\n",
    "\n",
    "            val_pred = discriminator.batchClassify(val_inp)\n",
    "            print(' average_loss = %.4f, train_acc = %.4f, val_acc = %.4f' % (total_loss, total_acc, torch.sum((val_pred>0.5)==(val_target>0.5)).data[0]/200.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T03:40:02.373429Z",
     "start_time": "2018-06-18T16:13:58.919862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Generator MLE Training...\n",
      "epoch 1 : .......... average_train_NLL = 6.8153, oracle_sample_NLL = 14.5579\n",
      "epoch 2 : .......... average_train_NLL = 6.1321, oracle_sample_NLL = 13.5007\n",
      "epoch 3 : .......... average_train_NLL = 5.7977, oracle_sample_NLL = 12.8886\n",
      "epoch 4 : .......... average_train_NLL = 5.5862, oracle_sample_NLL = 12.5322\n",
      "epoch 5 : .......... average_train_NLL = 5.4373, oracle_sample_NLL = 12.2580\n",
      "epoch 6 : .......... average_train_NLL = 5.3256, oracle_sample_NLL = 12.0543\n",
      "epoch 7 : .......... average_train_NLL = 5.2375, oracle_sample_NLL = 11.9010\n",
      "epoch 8 : .......... average_train_NLL = 5.1659, oracle_sample_NLL = 11.7473\n",
      "epoch 9 : .......... average_train_NLL = 5.1053, oracle_sample_NLL = 11.6427\n",
      "epoch 10 : .......... average_train_NLL = 5.0544, oracle_sample_NLL = 11.6157\n",
      "epoch 11 : .......... average_train_NLL = 5.0113, oracle_sample_NLL = 11.5355\n",
      "epoch 12 : .......... average_train_NLL = 4.9741, oracle_sample_NLL = 11.5011\n",
      "epoch 13 : .......... average_train_NLL = 4.9423, oracle_sample_NLL = 11.4498\n",
      "epoch 14 : .......... average_train_NLL = 4.9141, oracle_sample_NLL = 11.4033\n",
      "epoch 15 : .......... average_train_NLL = 4.8881, oracle_sample_NLL = 11.3569\n",
      "epoch 16 : .......... average_train_NLL = 4.8650, oracle_sample_NLL = 11.3028\n",
      "epoch 17 : .......... average_train_NLL = 4.8446, oracle_sample_NLL = 11.2661\n",
      "epoch 18 : .......... average_train_NLL = 4.8263, oracle_sample_NLL = 11.2419\n",
      "epoch 19 : .......... average_train_NLL = 4.8088, oracle_sample_NLL = 11.2691\n",
      "epoch 20 : .......... average_train_NLL = 4.7929, oracle_sample_NLL = 11.2405\n",
      "epoch 21 : .......... average_train_NLL = 4.7791, oracle_sample_NLL = 11.1899\n",
      "epoch 22 : .......... average_train_NLL = 4.7646, oracle_sample_NLL = 11.1539\n",
      "epoch 23 : .......... average_train_NLL = 4.7524, oracle_sample_NLL = 11.1358\n",
      "epoch 24 : .......... average_train_NLL = 4.7417, oracle_sample_NLL = 11.1090\n",
      "epoch 25 : .......... average_train_NLL = 4.7293, oracle_sample_NLL = 11.1028\n",
      "epoch 26 : .......... average_train_NLL = 4.7187, oracle_sample_NLL = 11.0990\n",
      "epoch 27 : .......... average_train_NLL = 4.7087, oracle_sample_NLL = 11.1135\n",
      "epoch 28 : .......... average_train_NLL = 4.7019, oracle_sample_NLL = 11.1018\n",
      "epoch 29 : .......... average_train_NLL = 4.6909, oracle_sample_NLL = 11.0568\n",
      "epoch 30 : .......... average_train_NLL = 4.6851, oracle_sample_NLL = 11.0198\n",
      "epoch 31 : .......... average_train_NLL = 4.6774, oracle_sample_NLL = 11.0350\n",
      "epoch 32 : .......... average_train_NLL = 4.6711, oracle_sample_NLL = 11.0350\n",
      "epoch 33 : .......... average_train_NLL = 4.6628, oracle_sample_NLL = 11.0413\n",
      "epoch 34 : .......... average_train_NLL = 4.6535, oracle_sample_NLL = 11.0437\n",
      "epoch 35 : .......... average_train_NLL = 4.6500, oracle_sample_NLL = 11.0076\n",
      "epoch 36 : .......... average_train_NLL = 4.6430, oracle_sample_NLL = 11.0360\n",
      "epoch 37 : .......... average_train_NLL = 4.6369, oracle_sample_NLL = 11.0210\n",
      "epoch 38 : .......... average_train_NLL = 4.6328, oracle_sample_NLL = 11.0498\n",
      "epoch 39 : .......... average_train_NLL = 4.6281, oracle_sample_NLL = 11.0159\n",
      "epoch 40 : .......... average_train_NLL = 4.6244, oracle_sample_NLL = 10.9633\n",
      "epoch 41 : .......... average_train_NLL = 4.6199, oracle_sample_NLL = 10.9652\n",
      "epoch 42 : .......... average_train_NLL = 4.6172, oracle_sample_NLL = 10.9577\n",
      "epoch 43 : .......... average_train_NLL = 4.6101, oracle_sample_NLL = 10.9666\n",
      "epoch 44 : .......... average_train_NLL = 4.6021, oracle_sample_NLL = 10.9734\n",
      "epoch 45 : .......... average_train_NLL = 4.6001, oracle_sample_NLL = 10.9722\n",
      "epoch 46 : .......... average_train_NLL = 4.5966, oracle_sample_NLL = 10.9438\n",
      "epoch 47 : .......... average_train_NLL = 4.5937, oracle_sample_NLL = 10.9395\n",
      "epoch 48 : .......... average_train_NLL = 4.5906, oracle_sample_NLL = 10.9272\n",
      "epoch 49 : .......... average_train_NLL = 4.5895, oracle_sample_NLL = 10.9595\n",
      "epoch 50 : .......... average_train_NLL = 4.5857, oracle_sample_NLL = 10.9782\n",
      "epoch 51 : .......... average_train_NLL = 4.5803, oracle_sample_NLL = 10.9598\n",
      "epoch 52 : .......... average_train_NLL = 4.5767, oracle_sample_NLL = 10.9253\n",
      "epoch 53 : .......... average_train_NLL = 4.5729, oracle_sample_NLL = 10.9480\n",
      "epoch 54 : .......... average_train_NLL = 4.5725, oracle_sample_NLL = 10.9116\n",
      "epoch 55 : .......... average_train_NLL = 4.5671, oracle_sample_NLL = 10.8942\n",
      "epoch 56 : .......... average_train_NLL = 4.5620, oracle_sample_NLL = 10.9064\n",
      "epoch 57 : .......... average_train_NLL = 4.5612, oracle_sample_NLL = 10.9192\n",
      "epoch 58 : .......... average_train_NLL = 4.5597, oracle_sample_NLL = 10.9088\n",
      "epoch 59 : .......... average_train_NLL = 4.5558, oracle_sample_NLL = 10.8823\n",
      "epoch 60 : .......... average_train_NLL = 4.5571, oracle_sample_NLL = 10.8868\n",
      "epoch 61 : .......... average_train_NLL = 4.5523, oracle_sample_NLL = 10.9217\n",
      "epoch 62 : .......... average_train_NLL = 4.5501, oracle_sample_NLL = 10.9067\n",
      "epoch 63 : .......... average_train_NLL = 4.5478, oracle_sample_NLL = 10.8834\n",
      "epoch 64 : .......... average_train_NLL = 4.5403, oracle_sample_NLL = 10.8834\n",
      "epoch 65 : .......... average_train_NLL = 4.5385, oracle_sample_NLL = 10.8546\n",
      "epoch 66 : .......... average_train_NLL = 4.5445, oracle_sample_NLL = 10.8975\n",
      "epoch 67 : .......... average_train_NLL = 4.5414, oracle_sample_NLL = 10.9084\n",
      "epoch 68 : .......... average_train_NLL = 4.5381, oracle_sample_NLL = 10.8771\n",
      "epoch 69 : .......... average_train_NLL = 4.5344, oracle_sample_NLL = 10.8965\n",
      "epoch 70 : .......... average_train_NLL = 4.5354, oracle_sample_NLL = 10.9112\n",
      "epoch 71 : .......... average_train_NLL = 4.5317, oracle_sample_NLL = 10.9287\n",
      "epoch 72 : .......... average_train_NLL = 4.5359, oracle_sample_NLL = 10.9279\n",
      "epoch 73 : .......... average_train_NLL = 4.5305, oracle_sample_NLL = 10.9209\n",
      "epoch 74 : .......... average_train_NLL = 4.5290, oracle_sample_NLL = 10.8614\n",
      "epoch 75 : .......... average_train_NLL = 4.5202, oracle_sample_NLL = 10.8887\n",
      "epoch 76 : .......... average_train_NLL = 4.5246, oracle_sample_NLL = 10.8899\n",
      "epoch 77 : .......... average_train_NLL = 4.5273, oracle_sample_NLL = 10.9074\n",
      "epoch 78 : .......... average_train_NLL = 4.5222, oracle_sample_NLL = 10.8719\n",
      "epoch 79 : .......... average_train_NLL = 4.5235, oracle_sample_NLL = 10.8882\n",
      "epoch 80 : .......... average_train_NLL = 4.5177, oracle_sample_NLL = 10.8629\n",
      "epoch 81 : .......... average_train_NLL = 4.5149, oracle_sample_NLL = 10.8442\n",
      "epoch 82 : .......... average_train_NLL = 4.5152, oracle_sample_NLL = 10.8941\n",
      "epoch 83 : .......... average_train_NLL = 4.5161, oracle_sample_NLL = 10.8948\n",
      "epoch 84 : .......... average_train_NLL = 4.5107, oracle_sample_NLL = 10.8466\n",
      "epoch 85 : .......... average_train_NLL = 4.5076, oracle_sample_NLL = 10.9100\n",
      "epoch 86 : .......... average_train_NLL = 4.5077, oracle_sample_NLL = 10.8981\n",
      "epoch 87 : .......... average_train_NLL = 4.5084, oracle_sample_NLL = 10.8927\n",
      "epoch 88 : .......... average_train_NLL = 4.5048, oracle_sample_NLL = 10.8817\n",
      "epoch 89 : .......... average_train_NLL = 4.5084, oracle_sample_NLL = 10.8730\n",
      "epoch 90 : .......... average_train_NLL = 4.5061, oracle_sample_NLL = 10.8731\n",
      "epoch 91 : .......... average_train_NLL = 4.5059, oracle_sample_NLL = 10.9104\n",
      "epoch 92 : .......... average_train_NLL = 4.4998, oracle_sample_NLL = 10.8731\n",
      "epoch 93 : .......... average_train_NLL = 4.5024, oracle_sample_NLL = 10.9130\n",
      "epoch 94 : .......... average_train_NLL = 4.4972, oracle_sample_NLL = 10.8621\n",
      "epoch 95 : .......... average_train_NLL = 4.4983, oracle_sample_NLL = 10.8953\n",
      "epoch 96 : .......... average_train_NLL = 4.4981, oracle_sample_NLL = 10.8557\n",
      "epoch 97 : .......... average_train_NLL = 4.4912, oracle_sample_NLL = 10.8197\n",
      "epoch 98 : .......... average_train_NLL = 4.5039, oracle_sample_NLL = 10.8532\n",
      "epoch 99 : .......... average_train_NLL = 4.4984, oracle_sample_NLL = 10.8383\n",
      "epoch 100 : .......... average_train_NLL = 4.4911, oracle_sample_NLL = 10.8524\n",
      "\n",
      "Starting Discriminator Training...\n",
      "d-step 1 epoch 1 : .......... average_loss = 0.6856, train_acc = 0.5511, val_acc = 0.5850\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.6538, train_acc = 0.6162, val_acc = 0.5850\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.6212, train_acc = 0.6609, val_acc = 0.6050\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.6290, train_acc = 0.6524, val_acc = 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d-step 2 epoch 2 : .......... average_loss = 0.6019, train_acc = 0.6770, val_acc = 0.5700\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.5728, train_acc = 0.7067, val_acc = 0.6100\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.5847, train_acc = 0.6935, val_acc = 0.6100\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.5578, train_acc = 0.7179, val_acc = 0.6200\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.5294, train_acc = 0.7415, val_acc = 0.6250\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.5425, train_acc = 0.7320, val_acc = 0.6250\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.5146, train_acc = 0.7515, val_acc = 0.6350\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.4894, train_acc = 0.7705, val_acc = 0.6550\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.5103, train_acc = 0.7563, val_acc = 0.6250\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.4828, train_acc = 0.7761, val_acc = 0.6550\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.4553, train_acc = 0.7921, val_acc = 0.6350\n",
      "d-step 6 epoch 1 : .......... average_loss = 0.4772, train_acc = 0.7784, val_acc = 0.6300\n",
      "d-step 6 epoch 2 : .......... average_loss = 0.4499, train_acc = 0.7981, val_acc = 0.6350\n",
      "d-step 6 epoch 3 : .......... average_loss = 0.4222, train_acc = 0.8138, val_acc = 0.6500\n",
      "d-step 7 epoch 1 : .......... average_loss = 0.4498, train_acc = 0.7993, val_acc = 0.6400\n",
      "d-step 7 epoch 2 : .......... average_loss = 0.4204, train_acc = 0.8171, val_acc = 0.6350\n",
      "d-step 7 epoch 3 : .......... average_loss = 0.3943, train_acc = 0.8319, val_acc = 0.6100\n",
      "d-step 8 epoch 1 : .......... average_loss = 0.4245, train_acc = 0.8127, val_acc = 0.6400\n",
      "d-step 8 epoch 2 : .......... average_loss = 0.3958, train_acc = 0.8289, val_acc = 0.6450\n",
      "d-step 8 epoch 3 : .......... average_loss = 0.3673, train_acc = 0.8460, val_acc = 0.6450\n",
      "d-step 9 epoch 1 : .......... average_loss = 0.3929, train_acc = 0.8348, val_acc = 0.6250\n",
      "d-step 9 epoch 2 : .......... average_loss = 0.3620, train_acc = 0.8515, val_acc = 0.6050\n",
      "d-step 9 epoch 3 : .......... average_loss = 0.3365, train_acc = 0.8614, val_acc = 0.6300\n",
      "d-step 10 epoch 1 : .......... average_loss = 0.3726, train_acc = 0.8457, val_acc = 0.6400\n",
      "d-step 10 epoch 2 : .......... average_loss = 0.3416, train_acc = 0.8632, val_acc = 0.6500\n",
      "d-step 10 epoch 3 : .......... average_loss = 0.3162, train_acc = 0.8739, val_acc = 0.6200\n",
      "d-step 11 epoch 1 : .......... average_loss = 0.3504, train_acc = 0.8575, val_acc = 0.6250\n",
      "d-step 11 epoch 2 : .......... average_loss = 0.3188, train_acc = 0.8777, val_acc = 0.6300\n",
      "d-step 11 epoch 3 : .......... average_loss = 0.2931, train_acc = 0.8889, val_acc = 0.6350\n",
      "d-step 12 epoch 1 : .......... average_loss = 0.3293, train_acc = 0.8715, val_acc = 0.6400\n",
      "d-step 12 epoch 2 : .......... average_loss = 0.2957, train_acc = 0.8879, val_acc = 0.6100\n",
      "d-step 12 epoch 3 : .......... average_loss = 0.2712, train_acc = 0.8998, val_acc = 0.6500\n",
      "d-step 13 epoch 1 : .......... average_loss = 0.3034, train_acc = 0.8863, val_acc = 0.6250\n",
      "d-step 13 epoch 2 : .......... average_loss = 0.2732, train_acc = 0.9009, val_acc = 0.6550\n",
      "d-step 13 epoch 3 : .......... average_loss = 0.2478, train_acc = 0.9105, val_acc = 0.6000\n",
      "d-step 14 epoch 1 : .......... average_loss = 0.2867, train_acc = 0.8956, val_acc = 0.6150\n",
      "d-step 14 epoch 2 : .......... average_loss = 0.2551, train_acc = 0.9094, val_acc = 0.6250\n",
      "d-step 14 epoch 3 : .......... average_loss = 0.2348, train_acc = 0.9187, val_acc = 0.6100\n",
      "d-step 15 epoch 1 : .......... average_loss = 0.2827, train_acc = 0.8995, val_acc = 0.6450\n",
      "d-step 15 epoch 2 : .......... average_loss = 0.2501, train_acc = 0.9134, val_acc = 0.6700\n",
      "d-step 15 epoch 3 : .......... average_loss = 0.2259, train_acc = 0.9223, val_acc = 0.6350\n",
      "d-step 16 epoch 1 : .......... average_loss = 0.2605, train_acc = 0.9084, val_acc = 0.6250\n",
      "d-step 16 epoch 2 : .......... average_loss = 0.2271, train_acc = 0.9245, val_acc = 0.6300\n",
      "d-step 16 epoch 3 : .......... average_loss = 0.2050, train_acc = 0.9335, val_acc = 0.6350\n",
      "d-step 17 epoch 1 : .......... average_loss = 0.2475, train_acc = 0.9177, val_acc = 0.6400\n",
      "d-step 17 epoch 2 : .......... average_loss = 0.2185, train_acc = 0.9296, val_acc = 0.6250\n",
      "d-step 17 epoch 3 : .......... average_loss = 0.1974, train_acc = 0.9375, val_acc = 0.6400\n",
      "d-step 18 epoch 1 : .......... average_loss = 0.2435, train_acc = 0.9188, val_acc = 0.6300\n",
      "d-step 18 epoch 2 : .......... average_loss = 0.2150, train_acc = 0.9313, val_acc = 0.6300\n",
      "d-step 18 epoch 3 : .......... average_loss = 0.1902, train_acc = 0.9420, val_acc = 0.6250\n",
      "d-step 19 epoch 1 : .......... average_loss = 0.2358, train_acc = 0.9245, val_acc = 0.6150\n",
      "d-step 19 epoch 2 : .......... average_loss = 0.2045, train_acc = 0.9365, val_acc = 0.6400\n",
      "d-step 19 epoch 3 : .......... average_loss = 0.1840, train_acc = 0.9440, val_acc = 0.6450\n",
      "d-step 20 epoch 1 : .......... average_loss = 0.2258, train_acc = 0.9284, val_acc = 0.6200\n",
      "d-step 20 epoch 2 : .......... average_loss = 0.1978, train_acc = 0.9404, val_acc = 0.6350\n",
      "d-step 20 epoch 3 : .......... average_loss = 0.1789, train_acc = 0.9472, val_acc = 0.6400\n",
      "d-step 21 epoch 1 : .......... average_loss = 0.2135, train_acc = 0.9345, val_acc = 0.6100\n",
      "d-step 21 epoch 2 : .......... average_loss = 0.1869, train_acc = 0.9433, val_acc = 0.6350\n",
      "d-step 21 epoch 3 : .......... average_loss = 0.1677, train_acc = 0.9515, val_acc = 0.6250\n",
      "d-step 22 epoch 1 : .......... average_loss = 0.1944, train_acc = 0.9405, val_acc = 0.6250\n",
      "d-step 22 epoch 2 : .......... average_loss = 0.1696, train_acc = 0.9478, val_acc = 0.6300\n",
      "d-step 22 epoch 3 : .......... average_loss = 0.1458, train_acc = 0.9579, val_acc = 0.6000\n",
      "d-step 23 epoch 1 : .......... average_loss = 0.1947, train_acc = 0.9410, val_acc = 0.6100\n",
      "d-step 23 epoch 2 : .......... average_loss = 0.1678, train_acc = 0.9483, val_acc = 0.5850\n",
      "d-step 23 epoch 3 : .......... average_loss = 0.1481, train_acc = 0.9579, val_acc = 0.6050\n",
      "d-step 24 epoch 1 : .......... average_loss = 0.1869, train_acc = 0.9436, val_acc = 0.6000\n",
      "d-step 24 epoch 2 : .......... average_loss = 0.1585, train_acc = 0.9546, val_acc = 0.5900\n",
      "d-step 24 epoch 3 : .......... average_loss = 0.1401, train_acc = 0.9600, val_acc = 0.6000\n",
      "d-step 25 epoch 1 : .......... average_loss = 0.1896, train_acc = 0.9452, val_acc = 0.6050\n",
      "d-step 25 epoch 2 : .......... average_loss = 0.1669, train_acc = 0.9527, val_acc = 0.6100\n",
      "d-step 25 epoch 3 : .......... average_loss = 0.1467, train_acc = 0.9601, val_acc = 0.5900\n",
      "d-step 26 epoch 1 : .......... average_loss = 0.1730, train_acc = 0.9505, val_acc = 0.5800\n",
      "d-step 26 epoch 2 : .......... average_loss = 0.1503, train_acc = 0.9587, val_acc = 0.6200\n",
      "d-step 26 epoch 3 : .......... average_loss = 0.1327, train_acc = 0.9637, val_acc = 0.6050\n",
      "d-step 27 epoch 1 : .......... average_loss = 0.1705, train_acc = 0.9537, val_acc = 0.6200\n",
      "d-step 27 epoch 2 : .......... average_loss = 0.1478, train_acc = 0.9597, val_acc = 0.6150\n",
      "d-step 27 epoch 3 : .......... average_loss = 0.1286, train_acc = 0.9670, val_acc = 0.6200\n",
      "d-step 28 epoch 1 : .......... average_loss = 0.1713, train_acc = 0.9498, val_acc = 0.6250\n",
      "d-step 28 epoch 2 : .......... average_loss = 0.1470, train_acc = 0.9575, val_acc = 0.6150\n",
      "d-step 28 epoch 3 : .......... average_loss = 0.1269, train_acc = 0.9644, val_acc = 0.6100\n",
      "d-step 29 epoch 1 : .......... average_loss = 0.1653, train_acc = 0.9533, val_acc = 0.6050\n",
      "d-step 29 epoch 2 : .......... average_loss = 0.1434, train_acc = 0.9601, val_acc = 0.6200\n",
      "d-step 29 epoch 3 : .......... average_loss = 0.1262, train_acc = 0.9646, val_acc = 0.6100\n",
      "d-step 30 epoch 1 : .......... average_loss = 0.1630, train_acc = 0.9551, val_acc = 0.5900\n",
      "d-step 30 epoch 2 : .......... average_loss = 0.1407, train_acc = 0.9613, val_acc = 0.6050\n",
      "d-step 30 epoch 3 : .......... average_loss = 0.1207, train_acc = 0.9677, val_acc = 0.5800\n",
      "d-step 31 epoch 1 : .......... average_loss = 0.1512, train_acc = 0.9571, val_acc = 0.6050\n",
      "d-step 31 epoch 2 : .......... average_loss = 0.1304, train_acc = 0.9639, val_acc = 0.6300\n",
      "d-step 31 epoch 3 : .......... average_loss = 0.1126, train_acc = 0.9705, val_acc = 0.6150\n",
      "d-step 32 epoch 1 : .......... average_loss = 0.1558, train_acc = 0.9573, val_acc = 0.5900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d-step 32 epoch 2 : .......... average_loss = 0.1331, train_acc = 0.9648, val_acc = 0.5950\n",
      "d-step 32 epoch 3 : .......... average_loss = 0.1171, train_acc = 0.9699, val_acc = 0.5950\n",
      "d-step 33 epoch 1 : .......... average_loss = 0.1443, train_acc = 0.9625, val_acc = 0.6000\n",
      "d-step 33 epoch 2 : .......... average_loss = 0.1211, train_acc = 0.9689, val_acc = 0.6000\n",
      "d-step 33 epoch 3 : .......... average_loss = 0.1062, train_acc = 0.9728, val_acc = 0.6200\n",
      "d-step 34 epoch 1 : .......... average_loss = 0.1518, train_acc = 0.9574, val_acc = 0.5950\n",
      "d-step 34 epoch 2 : .......... average_loss = 0.1263, train_acc = 0.9669, val_acc = 0.5950\n",
      "d-step 34 epoch 3 : .......... average_loss = 0.1106, train_acc = 0.9709, val_acc = 0.5750\n",
      "d-step 35 epoch 1 : .......... average_loss = 0.1417, train_acc = 0.9600, val_acc = 0.5950\n",
      "d-step 35 epoch 2 : .......... average_loss = 0.1173, train_acc = 0.9689, val_acc = 0.6050\n",
      "d-step 35 epoch 3 : .......... average_loss = 0.1044, train_acc = 0.9721, val_acc = 0.6100\n",
      "d-step 36 epoch 1 : .......... average_loss = 0.1312, train_acc = 0.9647, val_acc = 0.6000\n",
      "d-step 36 epoch 2 : .......... average_loss = 0.1083, train_acc = 0.9727, val_acc = 0.5950\n",
      "d-step 36 epoch 3 : .......... average_loss = 0.0955, train_acc = 0.9757, val_acc = 0.5900\n",
      "d-step 37 epoch 1 : .......... average_loss = 0.1291, train_acc = 0.9664, val_acc = 0.5900\n",
      "d-step 37 epoch 2 : .......... average_loss = 0.1083, train_acc = 0.9717, val_acc = 0.6050\n",
      "d-step 37 epoch 3 : .......... average_loss = 0.0939, train_acc = 0.9758, val_acc = 0.6000\n",
      "d-step 38 epoch 1 : .......... average_loss = 0.1323, train_acc = 0.9655, val_acc = 0.5900\n",
      "d-step 38 epoch 2 : .......... average_loss = 0.1125, train_acc = 0.9703, val_acc = 0.5900\n",
      "d-step 38 epoch 3 : .......... average_loss = 0.0972, train_acc = 0.9748, val_acc = 0.5950\n",
      "d-step 39 epoch 1 : .......... average_loss = 0.1229, train_acc = 0.9683, val_acc = 0.5750\n",
      "d-step 39 epoch 2 : .......... average_loss = 0.1049, train_acc = 0.9729, val_acc = 0.6000\n",
      "d-step 39 epoch 3 : .......... average_loss = 0.0874, train_acc = 0.9769, val_acc = 0.6050\n",
      "d-step 40 epoch 1 : .......... average_loss = 0.1289, train_acc = 0.9668, val_acc = 0.5850\n",
      "d-step 40 epoch 2 : .......... average_loss = 0.1081, train_acc = 0.9722, val_acc = 0.5800\n",
      "d-step 40 epoch 3 : .......... average_loss = 0.0903, train_acc = 0.9768, val_acc = 0.5850\n",
      "d-step 41 epoch 1 : .......... average_loss = 0.1268, train_acc = 0.9688, val_acc = 0.5900\n",
      "d-step 41 epoch 2 : .......... average_loss = 0.1073, train_acc = 0.9741, val_acc = 0.5700\n",
      "d-step 41 epoch 3 : .......... average_loss = 0.0927, train_acc = 0.9775, val_acc = 0.5800\n",
      "d-step 42 epoch 1 : .......... average_loss = 0.1275, train_acc = 0.9684, val_acc = 0.5850\n",
      "d-step 42 epoch 2 : .......... average_loss = 0.1044, train_acc = 0.9728, val_acc = 0.6050\n",
      "d-step 42 epoch 3 : .......... average_loss = 0.0908, train_acc = 0.9766, val_acc = 0.5900\n",
      "d-step 43 epoch 1 : .......... average_loss = 0.1221, train_acc = 0.9678, val_acc = 0.5900\n",
      "d-step 43 epoch 2 : .......... average_loss = 0.1000, train_acc = 0.9732, val_acc = 0.5900\n",
      "d-step 43 epoch 3 : .......... average_loss = 0.0871, train_acc = 0.9770, val_acc = 0.5900\n",
      "d-step 44 epoch 1 : .......... average_loss = 0.1169, train_acc = 0.9688, val_acc = 0.6000\n",
      "d-step 44 epoch 2 : .......... average_loss = 0.0991, train_acc = 0.9747, val_acc = 0.6050\n",
      "d-step 44 epoch 3 : .......... average_loss = 0.0841, train_acc = 0.9777, val_acc = 0.6150\n",
      "d-step 45 epoch 1 : .......... average_loss = 0.1195, train_acc = 0.9698, val_acc = 0.5700\n",
      "d-step 45 epoch 2 : .......... average_loss = 0.1009, train_acc = 0.9748, val_acc = 0.5950\n",
      "d-step 45 epoch 3 : .......... average_loss = 0.0866, train_acc = 0.9781, val_acc = 0.5950\n",
      "d-step 46 epoch 1 : .......... average_loss = 0.1144, train_acc = 0.9728, val_acc = 0.5800\n",
      "d-step 46 epoch 2 : .......... average_loss = 0.0940, train_acc = 0.9771, val_acc = 0.5950\n",
      "d-step 46 epoch 3 : .......... average_loss = 0.0842, train_acc = 0.9806, val_acc = 0.6000\n",
      "d-step 47 epoch 1 : .......... average_loss = 0.1130, train_acc = 0.9710, val_acc = 0.5850\n",
      "d-step 47 epoch 2 : .......... average_loss = 0.0929, train_acc = 0.9758, val_acc = 0.5950\n",
      "d-step 47 epoch 3 : .......... average_loss = 0.0803, train_acc = 0.9796, val_acc = 0.5850\n",
      "d-step 48 epoch 1 : .......... average_loss = 0.1116, train_acc = 0.9727, val_acc = 0.5900\n",
      "d-step 48 epoch 2 : .......... average_loss = 0.0926, train_acc = 0.9769, val_acc = 0.5750\n",
      "d-step 48 epoch 3 : .......... average_loss = 0.0793, train_acc = 0.9806, val_acc = 0.5950\n",
      "d-step 49 epoch 1 : .......... average_loss = 0.1086, train_acc = 0.9734, val_acc = 0.5800\n",
      "d-step 49 epoch 2 : .......... average_loss = 0.0908, train_acc = 0.9772, val_acc = 0.5700\n",
      "d-step 49 epoch 3 : .......... average_loss = 0.0793, train_acc = 0.9801, val_acc = 0.5650\n",
      "d-step 50 epoch 1 : .......... average_loss = 0.1124, train_acc = 0.9716, val_acc = 0.5850\n",
      "d-step 50 epoch 2 : .......... average_loss = 0.0931, train_acc = 0.9776, val_acc = 0.5900\n",
      "d-step 50 epoch 3 : .......... average_loss = 0.0811, train_acc = 0.9805, val_acc = 0.6000\n",
      "\n",
      "Starting Adversarial Training...\n",
      "\n",
      "Initial Oracle Sample Loss : 10.8401\n",
      "\n",
      "--------\n",
      "EPOCH 1\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.8144\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.1009, train_acc = 0.9741, val_acc = 0.6250\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0832, train_acc = 0.9780, val_acc = 0.6300\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0710, train_acc = 0.9821, val_acc = 0.6450\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.1085, train_acc = 0.9716, val_acc = 0.6200\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0882, train_acc = 0.9784, val_acc = 0.6200\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0765, train_acc = 0.9818, val_acc = 0.6050\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.1066, train_acc = 0.9740, val_acc = 0.6250\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0900, train_acc = 0.9788, val_acc = 0.6250\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0769, train_acc = 0.9825, val_acc = 0.6200\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.1032, train_acc = 0.9736, val_acc = 0.6150\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0856, train_acc = 0.9777, val_acc = 0.6100\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0707, train_acc = 0.9822, val_acc = 0.6250\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.1041, train_acc = 0.9748, val_acc = 0.6250\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0873, train_acc = 0.9795, val_acc = 0.6100\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0751, train_acc = 0.9823, val_acc = 0.6100\n",
      "\n",
      "--------\n",
      "EPOCH 2\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.7834\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0999, train_acc = 0.9758, val_acc = 0.5950\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0823, train_acc = 0.9789, val_acc = 0.5900\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0685, train_acc = 0.9828, val_acc = 0.5900\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0951, train_acc = 0.9775, val_acc = 0.6000\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0814, train_acc = 0.9801, val_acc = 0.5850\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0697, train_acc = 0.9825, val_acc = 0.5950\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0969, train_acc = 0.9765, val_acc = 0.5700\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0805, train_acc = 0.9805, val_acc = 0.6100\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0681, train_acc = 0.9840, val_acc = 0.6000\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0918, train_acc = 0.9772, val_acc = 0.5950\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0764, train_acc = 0.9819, val_acc = 0.6050\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0657, train_acc = 0.9848, val_acc = 0.5950\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0972, train_acc = 0.9765, val_acc = 0.5750\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0828, train_acc = 0.9804, val_acc = 0.5850\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0689, train_acc = 0.9842, val_acc = 0.5950\n",
      "\n",
      "--------\n",
      "EPOCH 3\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.7449\n",
      "\n",
      "Adversarial Training Discriminator : \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d-step 1 epoch 1 : .......... average_loss = 0.0925, train_acc = 0.9781, val_acc = 0.6050\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0775, train_acc = 0.9809, val_acc = 0.6150\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0633, train_acc = 0.9852, val_acc = 0.6050\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0936, train_acc = 0.9767, val_acc = 0.6050\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0754, train_acc = 0.9809, val_acc = 0.6050\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0645, train_acc = 0.9839, val_acc = 0.6000\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0922, train_acc = 0.9766, val_acc = 0.6050\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0743, train_acc = 0.9818, val_acc = 0.6150\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0627, train_acc = 0.9846, val_acc = 0.6200\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0963, train_acc = 0.9783, val_acc = 0.6100\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0815, train_acc = 0.9815, val_acc = 0.6000\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0707, train_acc = 0.9828, val_acc = 0.6000\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0814, train_acc = 0.9791, val_acc = 0.6050\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0669, train_acc = 0.9831, val_acc = 0.6100\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0555, train_acc = 0.9871, val_acc = 0.6050\n",
      "\n",
      "--------\n",
      "EPOCH 4\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.6745\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0871, train_acc = 0.9797, val_acc = 0.6400\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0708, train_acc = 0.9830, val_acc = 0.6450\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0597, train_acc = 0.9861, val_acc = 0.6400\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0889, train_acc = 0.9792, val_acc = 0.6300\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0744, train_acc = 0.9831, val_acc = 0.6400\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0648, train_acc = 0.9848, val_acc = 0.6500\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0813, train_acc = 0.9805, val_acc = 0.6400\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0667, train_acc = 0.9849, val_acc = 0.6400\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0574, train_acc = 0.9869, val_acc = 0.6650\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0814, train_acc = 0.9808, val_acc = 0.6350\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0686, train_acc = 0.9835, val_acc = 0.6200\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0575, train_acc = 0.9866, val_acc = 0.6350\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0856, train_acc = 0.9798, val_acc = 0.6500\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0721, train_acc = 0.9835, val_acc = 0.6300\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0603, train_acc = 0.9859, val_acc = 0.6350\n",
      "\n",
      "--------\n",
      "EPOCH 5\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.6568\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0799, train_acc = 0.9811, val_acc = 0.6250\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0678, train_acc = 0.9831, val_acc = 0.6200\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0550, train_acc = 0.9877, val_acc = 0.6200\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0824, train_acc = 0.9808, val_acc = 0.6100\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0657, train_acc = 0.9848, val_acc = 0.6100\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0567, train_acc = 0.9872, val_acc = 0.6100\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0789, train_acc = 0.9813, val_acc = 0.6050\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0641, train_acc = 0.9846, val_acc = 0.6050\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0546, train_acc = 0.9871, val_acc = 0.6150\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0767, train_acc = 0.9825, val_acc = 0.6050\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0659, train_acc = 0.9846, val_acc = 0.6150\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0555, train_acc = 0.9871, val_acc = 0.6150\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0813, train_acc = 0.9807, val_acc = 0.6050\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0675, train_acc = 0.9835, val_acc = 0.6050\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0567, train_acc = 0.9868, val_acc = 0.6000\n",
      "\n",
      "--------\n",
      "EPOCH 6\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.5772\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0799, train_acc = 0.9807, val_acc = 0.5650\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0632, train_acc = 0.9853, val_acc = 0.5700\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0509, train_acc = 0.9879, val_acc = 0.5650\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0714, train_acc = 0.9829, val_acc = 0.5700\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0578, train_acc = 0.9867, val_acc = 0.5750\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0464, train_acc = 0.9892, val_acc = 0.5700\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0732, train_acc = 0.9824, val_acc = 0.5750\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0587, train_acc = 0.9857, val_acc = 0.5850\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0486, train_acc = 0.9889, val_acc = 0.5650\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0708, train_acc = 0.9835, val_acc = 0.5750\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0584, train_acc = 0.9862, val_acc = 0.5650\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0476, train_acc = 0.9887, val_acc = 0.5650\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0786, train_acc = 0.9815, val_acc = 0.5650\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0625, train_acc = 0.9857, val_acc = 0.5600\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0533, train_acc = 0.9876, val_acc = 0.5750\n",
      "\n",
      "--------\n",
      "EPOCH 7\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.4903\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0683, train_acc = 0.9843, val_acc = 0.5850\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0534, train_acc = 0.9876, val_acc = 0.6050\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0460, train_acc = 0.9891, val_acc = 0.6100\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0736, train_acc = 0.9832, val_acc = 0.6000\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0604, train_acc = 0.9854, val_acc = 0.6150\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0503, train_acc = 0.9879, val_acc = 0.5900\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0705, train_acc = 0.9840, val_acc = 0.6000\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0574, train_acc = 0.9862, val_acc = 0.6000\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0482, train_acc = 0.9891, val_acc = 0.6050\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0677, train_acc = 0.9846, val_acc = 0.6000\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0540, train_acc = 0.9883, val_acc = 0.6000\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0490, train_acc = 0.9891, val_acc = 0.6250\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0695, train_acc = 0.9835, val_acc = 0.6050\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0566, train_acc = 0.9863, val_acc = 0.6050\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0478, train_acc = 0.9887, val_acc = 0.6200\n",
      "\n",
      "--------\n",
      "EPOCH 8\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.4141\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0614, train_acc = 0.9861, val_acc = 0.5700\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0514, train_acc = 0.9881, val_acc = 0.5950\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0426, train_acc = 0.9902, val_acc = 0.5900\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0693, train_acc = 0.9839, val_acc = 0.6000\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0587, train_acc = 0.9859, val_acc = 0.6050\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0488, train_acc = 0.9890, val_acc = 0.5850\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0683, train_acc = 0.9838, val_acc = 0.5800\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0550, train_acc = 0.9873, val_acc = 0.5700\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0431, train_acc = 0.9902, val_acc = 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d-step 4 epoch 1 : .......... average_loss = 0.0621, train_acc = 0.9852, val_acc = 0.5750\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0486, train_acc = 0.9887, val_acc = 0.5750\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0411, train_acc = 0.9908, val_acc = 0.5800\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0605, train_acc = 0.9856, val_acc = 0.5600\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0475, train_acc = 0.9893, val_acc = 0.5850\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0405, train_acc = 0.9900, val_acc = 0.5900\n",
      "\n",
      "--------\n",
      "EPOCH 9\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.3903\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0674, train_acc = 0.9851, val_acc = 0.6100\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0545, train_acc = 0.9883, val_acc = 0.6150\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0463, train_acc = 0.9889, val_acc = 0.6300\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0587, train_acc = 0.9867, val_acc = 0.6350\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0463, train_acc = 0.9897, val_acc = 0.6200\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0391, train_acc = 0.9918, val_acc = 0.6250\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0661, train_acc = 0.9848, val_acc = 0.6150\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0526, train_acc = 0.9875, val_acc = 0.6200\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0452, train_acc = 0.9897, val_acc = 0.6250\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0636, train_acc = 0.9861, val_acc = 0.6150\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0508, train_acc = 0.9879, val_acc = 0.6200\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0420, train_acc = 0.9900, val_acc = 0.6350\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0575, train_acc = 0.9859, val_acc = 0.6150\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0451, train_acc = 0.9892, val_acc = 0.6150\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0381, train_acc = 0.9908, val_acc = 0.6100\n",
      "\n",
      "--------\n",
      "EPOCH 10\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.3377\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0574, train_acc = 0.9867, val_acc = 0.5850\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0450, train_acc = 0.9894, val_acc = 0.5850\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0368, train_acc = 0.9907, val_acc = 0.5800\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0581, train_acc = 0.9871, val_acc = 0.5750\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0470, train_acc = 0.9897, val_acc = 0.5850\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0390, train_acc = 0.9911, val_acc = 0.5850\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0547, train_acc = 0.9875, val_acc = 0.5750\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0449, train_acc = 0.9901, val_acc = 0.5750\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0378, train_acc = 0.9910, val_acc = 0.5800\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0641, train_acc = 0.9867, val_acc = 0.5750\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0515, train_acc = 0.9882, val_acc = 0.5800\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0445, train_acc = 0.9898, val_acc = 0.5550\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0585, train_acc = 0.9872, val_acc = 0.5750\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0468, train_acc = 0.9898, val_acc = 0.5750\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0391, train_acc = 0.9919, val_acc = 0.5800\n",
      "\n",
      "--------\n",
      "EPOCH 11\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.2290\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0580, train_acc = 0.9869, val_acc = 0.5900\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0459, train_acc = 0.9898, val_acc = 0.5900\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0388, train_acc = 0.9909, val_acc = 0.5900\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0599, train_acc = 0.9870, val_acc = 0.5850\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0484, train_acc = 0.9891, val_acc = 0.5750\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0383, train_acc = 0.9914, val_acc = 0.5900\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0643, train_acc = 0.9866, val_acc = 0.5700\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0521, train_acc = 0.9890, val_acc = 0.5900\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0430, train_acc = 0.9904, val_acc = 0.5950\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0514, train_acc = 0.9887, val_acc = 0.5950\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0418, train_acc = 0.9906, val_acc = 0.5850\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0344, train_acc = 0.9920, val_acc = 0.6000\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0625, train_acc = 0.9861, val_acc = 0.5800\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0480, train_acc = 0.9896, val_acc = 0.5700\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0401, train_acc = 0.9909, val_acc = 0.6000\n",
      "\n",
      "--------\n",
      "EPOCH 12\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.1964\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0589, train_acc = 0.9873, val_acc = 0.5650\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0488, train_acc = 0.9889, val_acc = 0.5650\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0409, train_acc = 0.9908, val_acc = 0.5600\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0581, train_acc = 0.9861, val_acc = 0.5600\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0462, train_acc = 0.9897, val_acc = 0.5600\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0392, train_acc = 0.9912, val_acc = 0.5700\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0551, train_acc = 0.9880, val_acc = 0.5650\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0441, train_acc = 0.9899, val_acc = 0.5600\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0360, train_acc = 0.9919, val_acc = 0.5650\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0535, train_acc = 0.9878, val_acc = 0.5750\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0421, train_acc = 0.9902, val_acc = 0.5650\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0356, train_acc = 0.9916, val_acc = 0.5700\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0585, train_acc = 0.9878, val_acc = 0.5700\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0466, train_acc = 0.9903, val_acc = 0.5600\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0407, train_acc = 0.9916, val_acc = 0.5700\n",
      "\n",
      "--------\n",
      "EPOCH 13\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.1999\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0552, train_acc = 0.9882, val_acc = 0.6300\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0438, train_acc = 0.9898, val_acc = 0.6250\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0375, train_acc = 0.9916, val_acc = 0.6200\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0573, train_acc = 0.9869, val_acc = 0.6300\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0464, train_acc = 0.9895, val_acc = 0.6300\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0382, train_acc = 0.9914, val_acc = 0.6250\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0519, train_acc = 0.9889, val_acc = 0.6250\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0405, train_acc = 0.9912, val_acc = 0.6300\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0342, train_acc = 0.9922, val_acc = 0.6250\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0465, train_acc = 0.9895, val_acc = 0.6400\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0380, train_acc = 0.9918, val_acc = 0.6250\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0319, train_acc = 0.9931, val_acc = 0.6300\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0505, train_acc = 0.9883, val_acc = 0.6200\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0400, train_acc = 0.9905, val_acc = 0.6300\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0343, train_acc = 0.9922, val_acc = 0.6250\n",
      "\n",
      "--------\n",
      "EPOCH 14\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.0973\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0470, train_acc = 0.9890, val_acc = 0.5550\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0371, train_acc = 0.9911, val_acc = 0.5750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d-step 1 epoch 3 : .......... average_loss = 0.0311, train_acc = 0.9927, val_acc = 0.5800\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0487, train_acc = 0.9900, val_acc = 0.5700\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0385, train_acc = 0.9919, val_acc = 0.5750\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0326, train_acc = 0.9927, val_acc = 0.5750\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0511, train_acc = 0.9889, val_acc = 0.5800\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0384, train_acc = 0.9908, val_acc = 0.5750\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0322, train_acc = 0.9928, val_acc = 0.5750\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0519, train_acc = 0.9882, val_acc = 0.5700\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0413, train_acc = 0.9906, val_acc = 0.5800\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0330, train_acc = 0.9921, val_acc = 0.5700\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0522, train_acc = 0.9886, val_acc = 0.5800\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0402, train_acc = 0.9916, val_acc = 0.5750\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0330, train_acc = 0.9927, val_acc = 0.5700\n",
      "\n",
      "--------\n",
      "EPOCH 15\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.0578\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0508, train_acc = 0.9888, val_acc = 0.6000\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0399, train_acc = 0.9903, val_acc = 0.5950\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0325, train_acc = 0.9921, val_acc = 0.5800\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0459, train_acc = 0.9901, val_acc = 0.5850\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0375, train_acc = 0.9916, val_acc = 0.5950\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0311, train_acc = 0.9929, val_acc = 0.6000\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0509, train_acc = 0.9889, val_acc = 0.5700\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0400, train_acc = 0.9915, val_acc = 0.5800\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0326, train_acc = 0.9929, val_acc = 0.6000\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0522, train_acc = 0.9889, val_acc = 0.5800\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0418, train_acc = 0.9911, val_acc = 0.5950\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0350, train_acc = 0.9927, val_acc = 0.6000\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0472, train_acc = 0.9901, val_acc = 0.5800\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0373, train_acc = 0.9915, val_acc = 0.5650\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0293, train_acc = 0.9934, val_acc = 0.5750\n",
      "\n",
      "--------\n",
      "EPOCH 16\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.1001\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0451, train_acc = 0.9899, val_acc = 0.6100\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0373, train_acc = 0.9918, val_acc = 0.6100\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0317, train_acc = 0.9925, val_acc = 0.6000\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0508, train_acc = 0.9899, val_acc = 0.6150\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0407, train_acc = 0.9913, val_acc = 0.5950\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0325, train_acc = 0.9933, val_acc = 0.6050\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0501, train_acc = 0.9889, val_acc = 0.5950\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0401, train_acc = 0.9902, val_acc = 0.5900\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0315, train_acc = 0.9923, val_acc = 0.6100\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0428, train_acc = 0.9906, val_acc = 0.5900\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0335, train_acc = 0.9925, val_acc = 0.6000\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0285, train_acc = 0.9937, val_acc = 0.6100\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0448, train_acc = 0.9907, val_acc = 0.6000\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0369, train_acc = 0.9926, val_acc = 0.6000\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0287, train_acc = 0.9934, val_acc = 0.6100\n",
      "\n",
      "--------\n",
      "EPOCH 17\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.0674\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0419, train_acc = 0.9912, val_acc = 0.5800\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0314, train_acc = 0.9928, val_acc = 0.5950\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0282, train_acc = 0.9937, val_acc = 0.5900\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0457, train_acc = 0.9905, val_acc = 0.5850\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0354, train_acc = 0.9929, val_acc = 0.5850\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0298, train_acc = 0.9939, val_acc = 0.5950\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0457, train_acc = 0.9900, val_acc = 0.5950\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0360, train_acc = 0.9925, val_acc = 0.6000\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0308, train_acc = 0.9938, val_acc = 0.5950\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0465, train_acc = 0.9900, val_acc = 0.5900\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0375, train_acc = 0.9921, val_acc = 0.5900\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0300, train_acc = 0.9935, val_acc = 0.5900\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0418, train_acc = 0.9908, val_acc = 0.5850\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0348, train_acc = 0.9920, val_acc = 0.5850\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0267, train_acc = 0.9940, val_acc = 0.5900\n",
      "\n",
      "--------\n",
      "EPOCH 18\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.0792\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0436, train_acc = 0.9907, val_acc = 0.6200\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0335, train_acc = 0.9924, val_acc = 0.6200\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0273, train_acc = 0.9944, val_acc = 0.6200\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0357, train_acc = 0.9923, val_acc = 0.6250\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0275, train_acc = 0.9942, val_acc = 0.6250\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0217, train_acc = 0.9955, val_acc = 0.6300\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0467, train_acc = 0.9897, val_acc = 0.6300\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0358, train_acc = 0.9927, val_acc = 0.6350\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0309, train_acc = 0.9928, val_acc = 0.6250\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0461, train_acc = 0.9896, val_acc = 0.6200\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0376, train_acc = 0.9913, val_acc = 0.6250\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0291, train_acc = 0.9936, val_acc = 0.6300\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0408, train_acc = 0.9916, val_acc = 0.6350\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0319, train_acc = 0.9934, val_acc = 0.6250\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0259, train_acc = 0.9944, val_acc = 0.6300\n",
      "\n",
      "--------\n",
      "EPOCH 19\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.0074\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0483, train_acc = 0.9901, val_acc = 0.5400\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0380, train_acc = 0.9920, val_acc = 0.5500\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0321, train_acc = 0.9927, val_acc = 0.5350\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0438, train_acc = 0.9906, val_acc = 0.5500\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0360, train_acc = 0.9927, val_acc = 0.5450\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0280, train_acc = 0.9939, val_acc = 0.5400\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0416, train_acc = 0.9907, val_acc = 0.5350\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0341, train_acc = 0.9921, val_acc = 0.5600\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0260, train_acc = 0.9947, val_acc = 0.5400\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0471, train_acc = 0.9907, val_acc = 0.5500\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0385, train_acc = 0.9920, val_acc = 0.5450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d-step 4 epoch 3 : .......... average_loss = 0.0334, train_acc = 0.9931, val_acc = 0.5350\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0428, train_acc = 0.9912, val_acc = 0.5400\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0345, train_acc = 0.9930, val_acc = 0.5600\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0282, train_acc = 0.9934, val_acc = 0.5600\n",
      "\n",
      "--------\n",
      "EPOCH 20\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.0086\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0415, train_acc = 0.9912, val_acc = 0.5750\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0337, train_acc = 0.9922, val_acc = 0.5800\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0270, train_acc = 0.9943, val_acc = 0.5950\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0406, train_acc = 0.9912, val_acc = 0.5750\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0315, train_acc = 0.9932, val_acc = 0.5900\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0251, train_acc = 0.9947, val_acc = 0.5850\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0371, train_acc = 0.9915, val_acc = 0.5800\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0292, train_acc = 0.9935, val_acc = 0.5900\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0228, train_acc = 0.9949, val_acc = 0.5900\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0416, train_acc = 0.9917, val_acc = 0.5850\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0336, train_acc = 0.9930, val_acc = 0.5800\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0281, train_acc = 0.9944, val_acc = 0.5950\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0350, train_acc = 0.9929, val_acc = 0.5850\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0267, train_acc = 0.9944, val_acc = 0.5900\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0215, train_acc = 0.9951, val_acc = 0.5800\n",
      "\n",
      "--------\n",
      "EPOCH 21\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.0271\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0392, train_acc = 0.9916, val_acc = 0.5750\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0290, train_acc = 0.9935, val_acc = 0.5800\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0242, train_acc = 0.9942, val_acc = 0.5800\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0378, train_acc = 0.9916, val_acc = 0.5850\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0293, train_acc = 0.9936, val_acc = 0.5850\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0243, train_acc = 0.9947, val_acc = 0.5850\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0385, train_acc = 0.9917, val_acc = 0.5700\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0307, train_acc = 0.9936, val_acc = 0.5900\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0246, train_acc = 0.9941, val_acc = 0.5850\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0359, train_acc = 0.9929, val_acc = 0.5750\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0293, train_acc = 0.9940, val_acc = 0.5950\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0235, train_acc = 0.9951, val_acc = 0.5850\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0385, train_acc = 0.9917, val_acc = 0.5700\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0310, train_acc = 0.9935, val_acc = 0.5800\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0248, train_acc = 0.9943, val_acc = 0.5850\n",
      "\n",
      "--------\n",
      "EPOCH 22\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9966\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0422, train_acc = 0.9910, val_acc = 0.5500\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0328, train_acc = 0.9932, val_acc = 0.5600\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0288, train_acc = 0.9936, val_acc = 0.5550\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0345, train_acc = 0.9927, val_acc = 0.5500\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0272, train_acc = 0.9943, val_acc = 0.5650\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0225, train_acc = 0.9950, val_acc = 0.5550\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0306, train_acc = 0.9935, val_acc = 0.5650\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0233, train_acc = 0.9942, val_acc = 0.5700\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0183, train_acc = 0.9954, val_acc = 0.5600\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0401, train_acc = 0.9925, val_acc = 0.5550\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0313, train_acc = 0.9934, val_acc = 0.5650\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0261, train_acc = 0.9949, val_acc = 0.5600\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0397, train_acc = 0.9918, val_acc = 0.5700\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0311, train_acc = 0.9931, val_acc = 0.5550\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0255, train_acc = 0.9942, val_acc = 0.5550\n",
      "\n",
      "--------\n",
      "EPOCH 23\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9600\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0370, train_acc = 0.9929, val_acc = 0.6000\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0303, train_acc = 0.9942, val_acc = 0.6050\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0245, train_acc = 0.9951, val_acc = 0.6050\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0376, train_acc = 0.9920, val_acc = 0.5850\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0302, train_acc = 0.9932, val_acc = 0.5900\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0233, train_acc = 0.9950, val_acc = 0.5850\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0371, train_acc = 0.9916, val_acc = 0.5950\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0311, train_acc = 0.9932, val_acc = 0.5900\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0228, train_acc = 0.9949, val_acc = 0.6000\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0385, train_acc = 0.9916, val_acc = 0.5900\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0305, train_acc = 0.9933, val_acc = 0.5850\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0241, train_acc = 0.9946, val_acc = 0.5950\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0353, train_acc = 0.9921, val_acc = 0.5850\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0276, train_acc = 0.9940, val_acc = 0.5950\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0223, train_acc = 0.9946, val_acc = 0.5900\n",
      "\n",
      "--------\n",
      "EPOCH 24\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9824\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0413, train_acc = 0.9921, val_acc = 0.5950\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0331, train_acc = 0.9933, val_acc = 0.6050\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0259, train_acc = 0.9950, val_acc = 0.6100\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0432, train_acc = 0.9905, val_acc = 0.5900\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0338, train_acc = 0.9926, val_acc = 0.6050\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0262, train_acc = 0.9945, val_acc = 0.6100\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0388, train_acc = 0.9921, val_acc = 0.6050\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0298, train_acc = 0.9929, val_acc = 0.6250\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0251, train_acc = 0.9948, val_acc = 0.5950\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0384, train_acc = 0.9919, val_acc = 0.6000\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0307, train_acc = 0.9931, val_acc = 0.6050\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0235, train_acc = 0.9947, val_acc = 0.5950\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0331, train_acc = 0.9929, val_acc = 0.6050\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0274, train_acc = 0.9942, val_acc = 0.6100\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0196, train_acc = 0.9957, val_acc = 0.6050\n",
      "\n",
      "--------\n",
      "EPOCH 25\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9557\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0446, train_acc = 0.9911, val_acc = 0.5850\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0357, train_acc = 0.9929, val_acc = 0.5700\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0284, train_acc = 0.9940, val_acc = 0.5650\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0389, train_acc = 0.9923, val_acc = 0.5850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d-step 2 epoch 2 : .......... average_loss = 0.0284, train_acc = 0.9940, val_acc = 0.5750\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0246, train_acc = 0.9943, val_acc = 0.5750\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0451, train_acc = 0.9910, val_acc = 0.5850\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0348, train_acc = 0.9925, val_acc = 0.5750\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0283, train_acc = 0.9940, val_acc = 0.5800\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0323, train_acc = 0.9929, val_acc = 0.5800\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0250, train_acc = 0.9943, val_acc = 0.5900\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0195, train_acc = 0.9958, val_acc = 0.6000\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0336, train_acc = 0.9931, val_acc = 0.5800\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0280, train_acc = 0.9938, val_acc = 0.5750\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0221, train_acc = 0.9955, val_acc = 0.5800\n",
      "\n",
      "--------\n",
      "EPOCH 26\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 10.0147\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0358, train_acc = 0.9924, val_acc = 0.6150\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0281, train_acc = 0.9936, val_acc = 0.5850\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0228, train_acc = 0.9953, val_acc = 0.6150\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0341, train_acc = 0.9919, val_acc = 0.6150\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0259, train_acc = 0.9941, val_acc = 0.6050\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0205, train_acc = 0.9951, val_acc = 0.6150\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0380, train_acc = 0.9922, val_acc = 0.5950\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0298, train_acc = 0.9940, val_acc = 0.6100\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0226, train_acc = 0.9946, val_acc = 0.6050\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0313, train_acc = 0.9930, val_acc = 0.6000\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0236, train_acc = 0.9948, val_acc = 0.6100\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0195, train_acc = 0.9954, val_acc = 0.6150\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0317, train_acc = 0.9928, val_acc = 0.6000\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0243, train_acc = 0.9950, val_acc = 0.6100\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0191, train_acc = 0.9952, val_acc = 0.5950\n",
      "\n",
      "--------\n",
      "EPOCH 27\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9527\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0346, train_acc = 0.9929, val_acc = 0.5300\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0263, train_acc = 0.9944, val_acc = 0.5300\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0222, train_acc = 0.9953, val_acc = 0.5350\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0366, train_acc = 0.9926, val_acc = 0.5250\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0275, train_acc = 0.9940, val_acc = 0.5300\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0227, train_acc = 0.9950, val_acc = 0.5250\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0338, train_acc = 0.9931, val_acc = 0.5250\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0263, train_acc = 0.9944, val_acc = 0.5400\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0202, train_acc = 0.9958, val_acc = 0.5350\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0382, train_acc = 0.9922, val_acc = 0.5300\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0297, train_acc = 0.9937, val_acc = 0.5300\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0254, train_acc = 0.9947, val_acc = 0.5400\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0333, train_acc = 0.9925, val_acc = 0.5400\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0255, train_acc = 0.9942, val_acc = 0.5350\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0206, train_acc = 0.9952, val_acc = 0.5350\n",
      "\n",
      "--------\n",
      "EPOCH 28\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9698\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0353, train_acc = 0.9932, val_acc = 0.6050\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0279, train_acc = 0.9943, val_acc = 0.5900\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0235, train_acc = 0.9949, val_acc = 0.6100\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0324, train_acc = 0.9933, val_acc = 0.6100\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0251, train_acc = 0.9946, val_acc = 0.6250\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0201, train_acc = 0.9960, val_acc = 0.6100\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0350, train_acc = 0.9930, val_acc = 0.5900\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0286, train_acc = 0.9941, val_acc = 0.5950\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0234, train_acc = 0.9950, val_acc = 0.5850\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0407, train_acc = 0.9923, val_acc = 0.6000\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0333, train_acc = 0.9936, val_acc = 0.6050\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0274, train_acc = 0.9947, val_acc = 0.6000\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0310, train_acc = 0.9933, val_acc = 0.5800\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0241, train_acc = 0.9950, val_acc = 0.5950\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0196, train_acc = 0.9956, val_acc = 0.5900\n",
      "\n",
      "--------\n",
      "EPOCH 29\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9690\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0339, train_acc = 0.9930, val_acc = 0.5850\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0250, train_acc = 0.9946, val_acc = 0.5850\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0188, train_acc = 0.9961, val_acc = 0.5950\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0336, train_acc = 0.9929, val_acc = 0.6000\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0259, train_acc = 0.9949, val_acc = 0.5900\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0224, train_acc = 0.9950, val_acc = 0.5900\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0302, train_acc = 0.9938, val_acc = 0.5900\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0238, train_acc = 0.9951, val_acc = 0.6000\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0191, train_acc = 0.9954, val_acc = 0.6000\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0306, train_acc = 0.9934, val_acc = 0.5750\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0230, train_acc = 0.9956, val_acc = 0.6050\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0196, train_acc = 0.9954, val_acc = 0.5900\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0317, train_acc = 0.9932, val_acc = 0.5750\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0234, train_acc = 0.9952, val_acc = 0.5850\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0202, train_acc = 0.9959, val_acc = 0.5950\n",
      "\n",
      "--------\n",
      "EPOCH 30\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9405\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0321, train_acc = 0.9931, val_acc = 0.5650\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0253, train_acc = 0.9947, val_acc = 0.5650\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0205, train_acc = 0.9961, val_acc = 0.5550\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0299, train_acc = 0.9939, val_acc = 0.5700\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0215, train_acc = 0.9954, val_acc = 0.5850\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0189, train_acc = 0.9954, val_acc = 0.5700\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0346, train_acc = 0.9931, val_acc = 0.5650\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0266, train_acc = 0.9939, val_acc = 0.5550\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0201, train_acc = 0.9956, val_acc = 0.5550\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0299, train_acc = 0.9939, val_acc = 0.5600\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0217, train_acc = 0.9952, val_acc = 0.5600\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0177, train_acc = 0.9963, val_acc = 0.5600\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0277, train_acc = 0.9937, val_acc = 0.5600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d-step 5 epoch 2 : .......... average_loss = 0.0210, train_acc = 0.9950, val_acc = 0.5500\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0172, train_acc = 0.9959, val_acc = 0.5600\n",
      "\n",
      "--------\n",
      "EPOCH 31\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9169\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0334, train_acc = 0.9931, val_acc = 0.5900\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0263, train_acc = 0.9945, val_acc = 0.5900\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0214, train_acc = 0.9952, val_acc = 0.5800\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0329, train_acc = 0.9929, val_acc = 0.5800\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0255, train_acc = 0.9946, val_acc = 0.5800\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0200, train_acc = 0.9959, val_acc = 0.5800\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0311, train_acc = 0.9931, val_acc = 0.5850\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0248, train_acc = 0.9947, val_acc = 0.5800\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0202, train_acc = 0.9959, val_acc = 0.5850\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0286, train_acc = 0.9942, val_acc = 0.5800\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0229, train_acc = 0.9950, val_acc = 0.5850\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0162, train_acc = 0.9968, val_acc = 0.5750\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0334, train_acc = 0.9930, val_acc = 0.5750\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0253, train_acc = 0.9949, val_acc = 0.5750\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0224, train_acc = 0.9960, val_acc = 0.5750\n",
      "\n",
      "--------\n",
      "EPOCH 32\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.8917\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0296, train_acc = 0.9934, val_acc = 0.5850\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0228, train_acc = 0.9949, val_acc = 0.6000\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0190, train_acc = 0.9954, val_acc = 0.6000\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0317, train_acc = 0.9932, val_acc = 0.6000\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0246, train_acc = 0.9950, val_acc = 0.5900\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0195, train_acc = 0.9960, val_acc = 0.6000\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0297, train_acc = 0.9942, val_acc = 0.6000\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0221, train_acc = 0.9953, val_acc = 0.6050\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0189, train_acc = 0.9959, val_acc = 0.6100\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0361, train_acc = 0.9931, val_acc = 0.6000\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0296, train_acc = 0.9937, val_acc = 0.6050\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0231, train_acc = 0.9950, val_acc = 0.6100\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0256, train_acc = 0.9942, val_acc = 0.6100\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0206, train_acc = 0.9953, val_acc = 0.6000\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0147, train_acc = 0.9971, val_acc = 0.6150\n",
      "\n",
      "--------\n",
      "EPOCH 33\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9005\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0360, train_acc = 0.9929, val_acc = 0.5850\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0276, train_acc = 0.9947, val_acc = 0.6000\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0226, train_acc = 0.9953, val_acc = 0.5850\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0300, train_acc = 0.9939, val_acc = 0.5800\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0246, train_acc = 0.9950, val_acc = 0.5700\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0187, train_acc = 0.9961, val_acc = 0.5900\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0313, train_acc = 0.9939, val_acc = 0.5850\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0251, train_acc = 0.9948, val_acc = 0.5850\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0186, train_acc = 0.9960, val_acc = 0.5850\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0321, train_acc = 0.9938, val_acc = 0.5850\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0251, train_acc = 0.9948, val_acc = 0.5900\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0205, train_acc = 0.9957, val_acc = 0.5900\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0290, train_acc = 0.9942, val_acc = 0.5850\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0219, train_acc = 0.9955, val_acc = 0.5950\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0176, train_acc = 0.9963, val_acc = 0.6050\n",
      "\n",
      "--------\n",
      "EPOCH 34\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9662\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0320, train_acc = 0.9935, val_acc = 0.5500\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0242, train_acc = 0.9950, val_acc = 0.5500\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0200, train_acc = 0.9952, val_acc = 0.5400\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0287, train_acc = 0.9937, val_acc = 0.5600\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0219, train_acc = 0.9951, val_acc = 0.5600\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0178, train_acc = 0.9961, val_acc = 0.5600\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0307, train_acc = 0.9944, val_acc = 0.5450\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0246, train_acc = 0.9957, val_acc = 0.5550\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0206, train_acc = 0.9960, val_acc = 0.5500\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0293, train_acc = 0.9943, val_acc = 0.5550\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0251, train_acc = 0.9948, val_acc = 0.5500\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0192, train_acc = 0.9960, val_acc = 0.5550\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0342, train_acc = 0.9929, val_acc = 0.5500\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0263, train_acc = 0.9948, val_acc = 0.5500\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0219, train_acc = 0.9952, val_acc = 0.5650\n",
      "\n",
      "--------\n",
      "EPOCH 35\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9295\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0289, train_acc = 0.9939, val_acc = 0.5850\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0209, train_acc = 0.9954, val_acc = 0.5750\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0168, train_acc = 0.9963, val_acc = 0.5950\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0287, train_acc = 0.9936, val_acc = 0.5950\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0225, train_acc = 0.9949, val_acc = 0.5900\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0176, train_acc = 0.9958, val_acc = 0.5850\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0291, train_acc = 0.9938, val_acc = 0.5850\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0211, train_acc = 0.9952, val_acc = 0.5900\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0162, train_acc = 0.9964, val_acc = 0.5950\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0291, train_acc = 0.9942, val_acc = 0.5900\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0226, train_acc = 0.9958, val_acc = 0.5850\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0188, train_acc = 0.9962, val_acc = 0.5950\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0284, train_acc = 0.9941, val_acc = 0.5950\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0217, train_acc = 0.9953, val_acc = 0.5900\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0182, train_acc = 0.9961, val_acc = 0.5800\n",
      "\n",
      "--------\n",
      "EPOCH 36\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9541\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0268, train_acc = 0.9939, val_acc = 0.5700\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0209, train_acc = 0.9956, val_acc = 0.5700\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0163, train_acc = 0.9962, val_acc = 0.5650\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0270, train_acc = 0.9940, val_acc = 0.5700\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0206, train_acc = 0.9953, val_acc = 0.5800\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0171, train_acc = 0.9967, val_acc = 0.5700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d-step 3 epoch 1 : .......... average_loss = 0.0325, train_acc = 0.9933, val_acc = 0.5650\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0241, train_acc = 0.9953, val_acc = 0.5700\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0214, train_acc = 0.9957, val_acc = 0.5600\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0276, train_acc = 0.9940, val_acc = 0.5600\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0217, train_acc = 0.9956, val_acc = 0.5650\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0163, train_acc = 0.9966, val_acc = 0.5650\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0294, train_acc = 0.9938, val_acc = 0.5650\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0211, train_acc = 0.9954, val_acc = 0.5700\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0177, train_acc = 0.9962, val_acc = 0.5600\n",
      "\n",
      "--------\n",
      "EPOCH 37\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.8889\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0301, train_acc = 0.9936, val_acc = 0.6000\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0229, train_acc = 0.9953, val_acc = 0.5850\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0177, train_acc = 0.9962, val_acc = 0.5900\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0245, train_acc = 0.9948, val_acc = 0.5800\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0199, train_acc = 0.9960, val_acc = 0.5750\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0159, train_acc = 0.9963, val_acc = 0.5850\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0294, train_acc = 0.9940, val_acc = 0.5800\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0229, train_acc = 0.9955, val_acc = 0.6000\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0180, train_acc = 0.9964, val_acc = 0.6000\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0286, train_acc = 0.9936, val_acc = 0.5850\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0210, train_acc = 0.9950, val_acc = 0.5800\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0168, train_acc = 0.9961, val_acc = 0.5750\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0328, train_acc = 0.9940, val_acc = 0.5700\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0258, train_acc = 0.9946, val_acc = 0.5800\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0210, train_acc = 0.9958, val_acc = 0.5900\n",
      "\n",
      "--------\n",
      "EPOCH 38\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9959\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0250, train_acc = 0.9946, val_acc = 0.6000\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0180, train_acc = 0.9954, val_acc = 0.5900\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0135, train_acc = 0.9972, val_acc = 0.5950\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0288, train_acc = 0.9940, val_acc = 0.5900\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0219, train_acc = 0.9956, val_acc = 0.5900\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0188, train_acc = 0.9967, val_acc = 0.6050\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0315, train_acc = 0.9931, val_acc = 0.5950\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0235, train_acc = 0.9948, val_acc = 0.5850\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0186, train_acc = 0.9961, val_acc = 0.5900\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0264, train_acc = 0.9948, val_acc = 0.5850\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0223, train_acc = 0.9955, val_acc = 0.5950\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0172, train_acc = 0.9966, val_acc = 0.5950\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0335, train_acc = 0.9935, val_acc = 0.5950\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0260, train_acc = 0.9949, val_acc = 0.5900\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0218, train_acc = 0.9956, val_acc = 0.6000\n",
      "\n",
      "--------\n",
      "EPOCH 39\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9154\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0272, train_acc = 0.9941, val_acc = 0.5650\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0208, train_acc = 0.9950, val_acc = 0.5700\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0160, train_acc = 0.9963, val_acc = 0.5650\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0255, train_acc = 0.9947, val_acc = 0.5550\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0177, train_acc = 0.9963, val_acc = 0.5550\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0162, train_acc = 0.9962, val_acc = 0.5600\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0249, train_acc = 0.9946, val_acc = 0.5500\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0177, train_acc = 0.9964, val_acc = 0.5500\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0139, train_acc = 0.9969, val_acc = 0.5550\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0265, train_acc = 0.9950, val_acc = 0.5550\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0196, train_acc = 0.9956, val_acc = 0.5650\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0163, train_acc = 0.9962, val_acc = 0.5600\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0243, train_acc = 0.9953, val_acc = 0.5500\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0177, train_acc = 0.9967, val_acc = 0.5600\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0151, train_acc = 0.9969, val_acc = 0.5450\n",
      "\n",
      "--------\n",
      "EPOCH 40\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9090\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0291, train_acc = 0.9942, val_acc = 0.5750\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0227, train_acc = 0.9954, val_acc = 0.5800\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0173, train_acc = 0.9964, val_acc = 0.5800\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0227, train_acc = 0.9952, val_acc = 0.5750\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0185, train_acc = 0.9960, val_acc = 0.5750\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0137, train_acc = 0.9972, val_acc = 0.5800\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0295, train_acc = 0.9942, val_acc = 0.5750\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0241, train_acc = 0.9947, val_acc = 0.5850\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0188, train_acc = 0.9959, val_acc = 0.5800\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0224, train_acc = 0.9955, val_acc = 0.5900\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0173, train_acc = 0.9963, val_acc = 0.5800\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0134, train_acc = 0.9972, val_acc = 0.5650\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0327, train_acc = 0.9935, val_acc = 0.5950\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0247, train_acc = 0.9950, val_acc = 0.5850\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0189, train_acc = 0.9961, val_acc = 0.5900\n",
      "\n",
      "--------\n",
      "EPOCH 41\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9254\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0282, train_acc = 0.9948, val_acc = 0.5350\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0222, train_acc = 0.9957, val_acc = 0.5550\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0175, train_acc = 0.9967, val_acc = 0.5500\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0258, train_acc = 0.9950, val_acc = 0.5300\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0217, train_acc = 0.9956, val_acc = 0.5400\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0162, train_acc = 0.9968, val_acc = 0.5500\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0288, train_acc = 0.9943, val_acc = 0.5300\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0222, train_acc = 0.9958, val_acc = 0.5400\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0193, train_acc = 0.9966, val_acc = 0.5450\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0258, train_acc = 0.9941, val_acc = 0.5500\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0190, train_acc = 0.9960, val_acc = 0.5550\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0147, train_acc = 0.9969, val_acc = 0.5450\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0268, train_acc = 0.9948, val_acc = 0.5350\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0186, train_acc = 0.9956, val_acc = 0.5400\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0157, train_acc = 0.9963, val_acc = 0.5500\n",
      "\n",
      "--------\n",
      "EPOCH 42\n",
      "--------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9700\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0249, train_acc = 0.9949, val_acc = 0.5750\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0197, train_acc = 0.9959, val_acc = 0.5750\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0161, train_acc = 0.9970, val_acc = 0.5700\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0277, train_acc = 0.9944, val_acc = 0.5650\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0215, train_acc = 0.9952, val_acc = 0.5750\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0159, train_acc = 0.9966, val_acc = 0.5650\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0275, train_acc = 0.9942, val_acc = 0.5650\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0211, train_acc = 0.9953, val_acc = 0.5700\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0164, train_acc = 0.9966, val_acc = 0.5650\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0298, train_acc = 0.9941, val_acc = 0.5850\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0229, train_acc = 0.9958, val_acc = 0.5600\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0186, train_acc = 0.9964, val_acc = 0.5800\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0242, train_acc = 0.9947, val_acc = 0.5650\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0178, train_acc = 0.9959, val_acc = 0.5650\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0164, train_acc = 0.9965, val_acc = 0.5750\n",
      "\n",
      "--------\n",
      "EPOCH 43\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9249\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0294, train_acc = 0.9946, val_acc = 0.5700\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0212, train_acc = 0.9960, val_acc = 0.5800\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0173, train_acc = 0.9963, val_acc = 0.5650\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0259, train_acc = 0.9945, val_acc = 0.5750\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0199, train_acc = 0.9959, val_acc = 0.5800\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0155, train_acc = 0.9965, val_acc = 0.5750\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0272, train_acc = 0.9949, val_acc = 0.5600\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0202, train_acc = 0.9960, val_acc = 0.5650\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0167, train_acc = 0.9968, val_acc = 0.5650\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0276, train_acc = 0.9949, val_acc = 0.5650\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0209, train_acc = 0.9955, val_acc = 0.5750\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0175, train_acc = 0.9965, val_acc = 0.5800\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0245, train_acc = 0.9949, val_acc = 0.5600\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0167, train_acc = 0.9962, val_acc = 0.5750\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0130, train_acc = 0.9970, val_acc = 0.5650\n",
      "\n",
      "--------\n",
      "EPOCH 44\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9345\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0278, train_acc = 0.9948, val_acc = 0.5650\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0212, train_acc = 0.9961, val_acc = 0.5750\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0175, train_acc = 0.9961, val_acc = 0.5750\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0255, train_acc = 0.9948, val_acc = 0.5750\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0174, train_acc = 0.9962, val_acc = 0.5650\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0150, train_acc = 0.9962, val_acc = 0.5600\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0256, train_acc = 0.9948, val_acc = 0.5650\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0194, train_acc = 0.9962, val_acc = 0.5700\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0146, train_acc = 0.9969, val_acc = 0.5750\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0273, train_acc = 0.9948, val_acc = 0.5600\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0218, train_acc = 0.9957, val_acc = 0.5750\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0179, train_acc = 0.9964, val_acc = 0.5750\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0275, train_acc = 0.9946, val_acc = 0.5450\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0206, train_acc = 0.9959, val_acc = 0.5500\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0177, train_acc = 0.9971, val_acc = 0.5650\n",
      "\n",
      "--------\n",
      "EPOCH 45\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9359\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0265, train_acc = 0.9942, val_acc = 0.5900\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0190, train_acc = 0.9961, val_acc = 0.5850\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0150, train_acc = 0.9969, val_acc = 0.5800\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0282, train_acc = 0.9948, val_acc = 0.5900\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0218, train_acc = 0.9956, val_acc = 0.5950\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0187, train_acc = 0.9963, val_acc = 0.5750\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0293, train_acc = 0.9946, val_acc = 0.5950\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0237, train_acc = 0.9959, val_acc = 0.5850\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0193, train_acc = 0.9962, val_acc = 0.5900\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0245, train_acc = 0.9946, val_acc = 0.5800\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0187, train_acc = 0.9961, val_acc = 0.5900\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0150, train_acc = 0.9965, val_acc = 0.5900\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0238, train_acc = 0.9950, val_acc = 0.5800\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0183, train_acc = 0.9962, val_acc = 0.5850\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0138, train_acc = 0.9970, val_acc = 0.5900\n",
      "\n",
      "--------\n",
      "EPOCH 46\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9793\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0281, train_acc = 0.9948, val_acc = 0.5700\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0222, train_acc = 0.9959, val_acc = 0.5750\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0197, train_acc = 0.9962, val_acc = 0.5650\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0291, train_acc = 0.9943, val_acc = 0.5500\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0229, train_acc = 0.9950, val_acc = 0.5600\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0175, train_acc = 0.9969, val_acc = 0.5750\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0253, train_acc = 0.9941, val_acc = 0.5650\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0186, train_acc = 0.9962, val_acc = 0.5650\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0149, train_acc = 0.9966, val_acc = 0.5650\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0280, train_acc = 0.9949, val_acc = 0.5700\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0214, train_acc = 0.9959, val_acc = 0.5550\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0178, train_acc = 0.9968, val_acc = 0.5600\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0252, train_acc = 0.9948, val_acc = 0.5600\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0199, train_acc = 0.9956, val_acc = 0.5550\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0154, train_acc = 0.9966, val_acc = 0.5550\n",
      "\n",
      "--------\n",
      "EPOCH 47\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9394\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0261, train_acc = 0.9950, val_acc = 0.5800\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0199, train_acc = 0.9961, val_acc = 0.5850\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0156, train_acc = 0.9966, val_acc = 0.5800\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0281, train_acc = 0.9940, val_acc = 0.5650\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0223, train_acc = 0.9955, val_acc = 0.5950\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0186, train_acc = 0.9958, val_acc = 0.5800\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0239, train_acc = 0.9950, val_acc = 0.5750\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0186, train_acc = 0.9958, val_acc = 0.5850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d-step 3 epoch 3 : .......... average_loss = 0.0137, train_acc = 0.9970, val_acc = 0.5800\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0305, train_acc = 0.9944, val_acc = 0.5700\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0231, train_acc = 0.9953, val_acc = 0.5700\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0195, train_acc = 0.9964, val_acc = 0.5650\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0262, train_acc = 0.9946, val_acc = 0.5650\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0199, train_acc = 0.9958, val_acc = 0.5700\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0169, train_acc = 0.9963, val_acc = 0.5700\n",
      "\n",
      "--------\n",
      "EPOCH 48\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9191\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0254, train_acc = 0.9950, val_acc = 0.5650\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0190, train_acc = 0.9964, val_acc = 0.5600\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0157, train_acc = 0.9967, val_acc = 0.5750\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0231, train_acc = 0.9951, val_acc = 0.5600\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0191, train_acc = 0.9960, val_acc = 0.5600\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0152, train_acc = 0.9967, val_acc = 0.5600\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0242, train_acc = 0.9950, val_acc = 0.5500\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0193, train_acc = 0.9961, val_acc = 0.5550\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0151, train_acc = 0.9970, val_acc = 0.5700\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0247, train_acc = 0.9949, val_acc = 0.5800\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0196, train_acc = 0.9957, val_acc = 0.5700\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0150, train_acc = 0.9970, val_acc = 0.5650\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0277, train_acc = 0.9949, val_acc = 0.5750\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0196, train_acc = 0.9959, val_acc = 0.5700\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0152, train_acc = 0.9969, val_acc = 0.5750\n",
      "\n",
      "--------\n",
      "EPOCH 49\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9150\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0267, train_acc = 0.9947, val_acc = 0.5900\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0188, train_acc = 0.9969, val_acc = 0.6100\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0171, train_acc = 0.9962, val_acc = 0.6100\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0216, train_acc = 0.9959, val_acc = 0.6050\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0155, train_acc = 0.9968, val_acc = 0.6000\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0117, train_acc = 0.9978, val_acc = 0.6150\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0296, train_acc = 0.9939, val_acc = 0.5950\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0222, train_acc = 0.9951, val_acc = 0.5950\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0171, train_acc = 0.9962, val_acc = 0.6000\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0237, train_acc = 0.9951, val_acc = 0.6100\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0183, train_acc = 0.9963, val_acc = 0.6100\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0147, train_acc = 0.9970, val_acc = 0.6100\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0264, train_acc = 0.9949, val_acc = 0.6050\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0196, train_acc = 0.9960, val_acc = 0.6000\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0163, train_acc = 0.9964, val_acc = 0.6050\n",
      "\n",
      "--------\n",
      "EPOCH 50\n",
      "--------\n",
      "\n",
      "Adversarial Training Generator :  oracle_sample_NLL = 9.9704\n",
      "\n",
      "Adversarial Training Discriminator : \n",
      "d-step 1 epoch 1 : .......... average_loss = 0.0250, train_acc = 0.9951, val_acc = 0.5550\n",
      "d-step 1 epoch 2 : .......... average_loss = 0.0182, train_acc = 0.9961, val_acc = 0.5600\n",
      "d-step 1 epoch 3 : .......... average_loss = 0.0147, train_acc = 0.9969, val_acc = 0.5700\n",
      "d-step 2 epoch 1 : .......... average_loss = 0.0280, train_acc = 0.9942, val_acc = 0.5600\n",
      "d-step 2 epoch 2 : .......... average_loss = 0.0227, train_acc = 0.9953, val_acc = 0.5650\n",
      "d-step 2 epoch 3 : .......... average_loss = 0.0169, train_acc = 0.9967, val_acc = 0.5650\n",
      "d-step 3 epoch 1 : .......... average_loss = 0.0235, train_acc = 0.9952, val_acc = 0.5650\n",
      "d-step 3 epoch 2 : .......... average_loss = 0.0179, train_acc = 0.9963, val_acc = 0.5550\n",
      "d-step 3 epoch 3 : .......... average_loss = 0.0158, train_acc = 0.9970, val_acc = 0.5650\n",
      "d-step 4 epoch 1 : .......... average_loss = 0.0239, train_acc = 0.9949, val_acc = 0.5550\n",
      "d-step 4 epoch 2 : .......... average_loss = 0.0189, train_acc = 0.9962, val_acc = 0.5700\n",
      "d-step 4 epoch 3 : .......... average_loss = 0.0141, train_acc = 0.9972, val_acc = 0.5700\n",
      "d-step 5 epoch 1 : .......... average_loss = 0.0218, train_acc = 0.9950, val_acc = 0.5650\n",
      "d-step 5 epoch 2 : .......... average_loss = 0.0162, train_acc = 0.9969, val_acc = 0.5700\n",
      "d-step 5 epoch 3 : .......... average_loss = 0.0135, train_acc = 0.9970, val_acc = 0.5750\n"
     ]
    }
   ],
   "source": [
    "oracle = Generator(GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
    "oracle.load_state_dict(torch.load(oracle_state_dict_path))\n",
    "oracle_samples = torch.load(oracle_samples_path).type(torch.LongTensor)\n",
    "# a new oracle can be generated by passing oracle_init=True in the generator constructor\n",
    "# samples for the new oracle can be generated using helpers.batchwise_sample()\n",
    "\n",
    "gen = Generator(GEN_EMBEDDING_DIM, GEN_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
    "dis = Discriminator(DIS_EMBEDDING_DIM, DIS_HIDDEN_DIM, VOCAB_SIZE, MAX_SEQ_LEN, gpu=CUDA)\n",
    "\n",
    "if CUDA:\n",
    "    oracle = oracle.cuda()\n",
    "    gen = gen.cuda()\n",
    "    dis = dis.cuda()\n",
    "    oracle_samples = oracle_samples.cuda()\n",
    "\n",
    "# GENERATOR MLE TRAINING\n",
    "print('Starting Generator MLE Training...')\n",
    "gen_optimizer = optim.Adam(gen.parameters(), lr=1e-2)\n",
    "train_generator_MLE(gen, gen_optimizer, oracle, oracle_samples, MLE_TRAIN_EPOCHS)\n",
    "\n",
    "torch.save(gen.state_dict(), pretrained_gen_path)\n",
    "gen.load_state_dict(torch.load(pretrained_gen_path))\n",
    "\n",
    "# PRETRAIN DISCRIMINATOR\n",
    "print('\\nStarting Discriminator Training...')\n",
    "dis_optimizer = optim.Adagrad(dis.parameters())\n",
    "train_discriminator(dis, dis_optimizer, oracle_samples, gen, oracle, 50, 3)\n",
    "\n",
    "torch.save(dis.state_dict(), pretrained_dis_path)\n",
    "dis.load_state_dict(torch.load(pretrained_dis_path))\n",
    "\n",
    "# ADVERSARIAL TRAINING\n",
    "print('\\nStarting Adversarial Training...')\n",
    "oracle_loss = batchwise_oracle_nll(gen, oracle, POS_NEG_SAMPLES, BATCH_SIZE, MAX_SEQ_LEN, start_letter=START_LETTER, gpu=CUDA)\n",
    "print('\\nInitial Oracle Sample Loss : %.4f' % oracle_loss)\n",
    "\n",
    "for epoch in range(ADV_TRAIN_EPOCHS):\n",
    "    print('\\n--------\\nEPOCH %d\\n--------' % (epoch+1))\n",
    "    # TRAIN GENERATOR\n",
    "    print('\\nAdversarial Training Generator : ', end='')\n",
    "    sys.stdout.flush()\n",
    "    train_generator_PG(gen, gen_optimizer, oracle, dis, 1)\n",
    "\n",
    "    # TRAIN DISCRIMINATOR\n",
    "    print('\\nAdversarial Training Discriminator : ')\n",
    "    train_discriminator(dis, dis_optimizer, oracle_samples, gen, oracle, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T14:27:27.143847Z",
     "start_time": "2018-06-16T14:27:27.139689Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
